{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchvision.transforms import v2\n",
    "#from torchmetrics.classification import BinaryF1Score, BinaryRecall, BinaryPrecision, BinaryAccuracy, AUROC\n",
    "from tqdm.auto import tqdm\n",
    "from dataset_dataloader import get_loader\n",
    "from utils import load_checkpoint, save_checkpoint, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 16\n",
    "# #RANDOM_SEED = 42\n",
    "METADATA_CSV_PATH = \"D:/ISIC 2024 - Skin Cancer Detection with 3D-TBP/Data/train-metadata.csv\"\n",
    "METADATA_CSV_PATH_50kSAMPLE = 'D:/ISIC 2024 - Skin Cancer Detection with 3D-TBP/EDA/isic2024_50ksample.csv'\n",
    "MODEL_SAVE_PATH = \"D:/ISIC 2024 - Skin Cancer Detection with 3D-TBP/model_resnet34_aug_2-1.pth\"\n",
    "LEARNING_RATE = 0.01\n",
    "CLASSES = 1\n",
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#meta_df_sample = pd.read_csv(METADATA_CSV_PATH_50kSAMPLE, low_memory=False)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_dl, val_dl, test_dl \u001b[38;5;241m=\u001b[39m \u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\Codebase\\Classification_v2\\dataset_dataloader.py:136\u001b[0m, in \u001b[0;36mget_loader\u001b[1;34m(batch_size, seed)\u001b[0m\n\u001b[0;32m     89\u001b[0m     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m     91\u001b[0m     return train_loader, val_loader, test_loader\n\u001b[0;32m     94\u001b[0m # class ISIC_2024_HDF5Dataset(Dataset):\n\u001b[0;32m     95\u001b[0m #     def __init__(self, file_path, label_csv=None, transform=None):\n\u001b[0;32m     96\u001b[0m #         self.file_path = file_path\n\u001b[0;32m     97\u001b[0m #         self.transform = transform\n\u001b[0;32m     98\u001b[0m         \n\u001b[0;32m     99\u001b[0m #         with h5py.File(self.file_path, 'r') as file:\n\u001b[0;32m    100\u001b[0m #             self.keys = list(file.keys())\n\u001b[0;32m    101\u001b[0m         \n\u001b[0;32m    102\u001b[0m #         if label_csv:\n\u001b[0;32m    103\u001b[0m #             self.labels_df = pd.read_csv(label_csv, low_memory=False)\n\u001b[0;32m    104\u001b[0m #             self.labels_df['isic_id'] = self.labels_df['isic_id'].str.replace('.jpg', '')\n\u001b[0;32m    105\u001b[0m #             self.labels_dict = dict(zip(self.labels_df['isic_id'], self.labels_df['target']))\n\u001b[0;32m    106\u001b[0m #         else:\n\u001b[0;32m    107\u001b[0m #             self.labels_dict = None\n\u001b[0;32m    108\u001b[0m     \n\u001b[0;32m    109\u001b[0m #     def __getitem__(self, index):\n\u001b[0;32m    110\u001b[0m #         with h5py.File(self.file_path, 'r') as file:\n\u001b[0;32m    111\u001b[0m #             key = self.keys[index]\n\u001b[0;32m    112\u001b[0m #             jpeg_data = file[key][()]\n\u001b[0;32m    113\u001b[0m #             image = Image.open(io.BytesIO(jpeg_data))\n\u001b[0;32m    114\u001b[0m #             image = np.array(image)\n\u001b[0;32m    115\u001b[0m         \n\u001b[0;32m    116\u001b[0m #         if self.transform:\n\u001b[0;32m    117\u001b[0m #             image = self.transform(image)\n\u001b[0;32m    118\u001b[0m         \n\u001b[0;32m    119\u001b[0m #         if self.labels_dict:\n\u001b[0;32m    120\u001b[0m #             label = self.labels_dict.get(key, -1)  # Use -1 if key not found\n\u001b[0;32m    121\u001b[0m #             return image, label\n\u001b[0;32m    122\u001b[0m #         else:\n\u001b[0;32m    123\u001b[0m #             return image, 0  # For test set without labels\n\u001b[0;32m    124\u001b[0m     \n\u001b[0;32m    125\u001b[0m #     def __len__(self):\n\u001b[0;32m    126\u001b[0m #         return len(self.keys)\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m # def get_loader(batch_size=16, seed=None):\n\u001b[0;32m    129\u001b[0m #     train_dataset = ISIC_2024_HDF5Dataset(TRAIN_DATA_PATH, label_csv=METADATA_CSV_PATH, transform=TRANS_TRAIN)\n\u001b[0;32m    130\u001b[0m #     test_dataset = ISIC_2024_HDF5Dataset(TEST_DATA_PATH, transform=TRANS_TEST)\n\u001b[0;32m    131\u001b[0m     \n\u001b[0;32m    132\u001b[0m #     # Split train dataset into train and validation\n\u001b[0;32m    133\u001b[0m #     train_idx, val_idx = train_test_split(\n\u001b[0;32m    134\u001b[0m #         range(len(train_dataset)),\n\u001b[0;32m    135\u001b[0m #         test_size=0.2,\n\u001b[1;32m--> 136\u001b[0m #         stratify=[train_dataset[i][1] for i in range(len(train_dataset))],\n\u001b[0;32m    137\u001b[0m #         random_state=seed\n\u001b[0;32m    138\u001b[0m #     )\n\u001b[0;32m    139\u001b[0m     \n\u001b[0;32m    140\u001b[0m #     train_subset = Subset(train_dataset, train_idx)\n\u001b[0;32m    141\u001b[0m #     val_subset = Subset(train_dataset, val_idx)\n\u001b[0;32m    142\u001b[0m     \n\u001b[0;32m    143\u001b[0m #     train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n\u001b[0;32m    144\u001b[0m #     val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m    145\u001b[0m #     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m #     return train_loader, val_loader, test_loader\n",
      "File \u001b[1;32md:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\Codebase\\Classification_v2\\dataset_dataloader.py:136\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     89\u001b[0m     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m     91\u001b[0m     return train_loader, val_loader, test_loader\n\u001b[0;32m     94\u001b[0m # class ISIC_2024_HDF5Dataset(Dataset):\n\u001b[0;32m     95\u001b[0m #     def __init__(self, file_path, label_csv=None, transform=None):\n\u001b[0;32m     96\u001b[0m #         self.file_path = file_path\n\u001b[0;32m     97\u001b[0m #         self.transform = transform\n\u001b[0;32m     98\u001b[0m         \n\u001b[0;32m     99\u001b[0m #         with h5py.File(self.file_path, 'r') as file:\n\u001b[0;32m    100\u001b[0m #             self.keys = list(file.keys())\n\u001b[0;32m    101\u001b[0m         \n\u001b[0;32m    102\u001b[0m #         if label_csv:\n\u001b[0;32m    103\u001b[0m #             self.labels_df = pd.read_csv(label_csv, low_memory=False)\n\u001b[0;32m    104\u001b[0m #             self.labels_df['isic_id'] = self.labels_df['isic_id'].str.replace('.jpg', '')\n\u001b[0;32m    105\u001b[0m #             self.labels_dict = dict(zip(self.labels_df['isic_id'], self.labels_df['target']))\n\u001b[0;32m    106\u001b[0m #         else:\n\u001b[0;32m    107\u001b[0m #             self.labels_dict = None\n\u001b[0;32m    108\u001b[0m     \n\u001b[0;32m    109\u001b[0m #     def __getitem__(self, index):\n\u001b[0;32m    110\u001b[0m #         with h5py.File(self.file_path, 'r') as file:\n\u001b[0;32m    111\u001b[0m #             key = self.keys[index]\n\u001b[0;32m    112\u001b[0m #             jpeg_data = file[key][()]\n\u001b[0;32m    113\u001b[0m #             image = Image.open(io.BytesIO(jpeg_data))\n\u001b[0;32m    114\u001b[0m #             image = np.array(image)\n\u001b[0;32m    115\u001b[0m         \n\u001b[0;32m    116\u001b[0m #         if self.transform:\n\u001b[0;32m    117\u001b[0m #             image = self.transform(image)\n\u001b[0;32m    118\u001b[0m         \n\u001b[0;32m    119\u001b[0m #         if self.labels_dict:\n\u001b[0;32m    120\u001b[0m #             label = self.labels_dict.get(key, -1)  # Use -1 if key not found\n\u001b[0;32m    121\u001b[0m #             return image, label\n\u001b[0;32m    122\u001b[0m #         else:\n\u001b[0;32m    123\u001b[0m #             return image, 0  # For test set without labels\n\u001b[0;32m    124\u001b[0m     \n\u001b[0;32m    125\u001b[0m #     def __len__(self):\n\u001b[0;32m    126\u001b[0m #         return len(self.keys)\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m # def get_loader(batch_size=16, seed=None):\n\u001b[0;32m    129\u001b[0m #     train_dataset = ISIC_2024_HDF5Dataset(TRAIN_DATA_PATH, label_csv=METADATA_CSV_PATH, transform=TRANS_TRAIN)\n\u001b[0;32m    130\u001b[0m #     test_dataset = ISIC_2024_HDF5Dataset(TEST_DATA_PATH, transform=TRANS_TEST)\n\u001b[0;32m    131\u001b[0m     \n\u001b[0;32m    132\u001b[0m #     # Split train dataset into train and validation\n\u001b[0;32m    133\u001b[0m #     train_idx, val_idx = train_test_split(\n\u001b[0;32m    134\u001b[0m #         range(len(train_dataset)),\n\u001b[0;32m    135\u001b[0m #         test_size=0.2,\n\u001b[1;32m--> 136\u001b[0m #         stratify=[train_dataset[i][1] for i in range(len(train_dataset))],\n\u001b[0;32m    137\u001b[0m #         random_state=seed\n\u001b[0;32m    138\u001b[0m #     )\n\u001b[0;32m    139\u001b[0m     \n\u001b[0;32m    140\u001b[0m #     train_subset = Subset(train_dataset, train_idx)\n\u001b[0;32m    141\u001b[0m #     val_subset = Subset(train_dataset, val_idx)\n\u001b[0;32m    142\u001b[0m     \n\u001b[0;32m    143\u001b[0m #     train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n\u001b[0;32m    144\u001b[0m #     val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m    145\u001b[0m #     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m #     return train_loader, val_loader, test_loader\n",
      "File \u001b[1;32md:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\Codebase\\Classification_v2\\dataset_dataloader.py:117\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     89\u001b[0m     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m     91\u001b[0m     return train_loader, val_loader, test_loader\n\u001b[0;32m     94\u001b[0m # class ISIC_2024_HDF5Dataset(Dataset):\n\u001b[0;32m     95\u001b[0m #     def __init__(self, file_path, label_csv=None, transform=None):\n\u001b[0;32m     96\u001b[0m #         self.file_path = file_path\n\u001b[0;32m     97\u001b[0m #         self.transform = transform\n\u001b[0;32m     98\u001b[0m         \n\u001b[0;32m     99\u001b[0m #         with h5py.File(self.file_path, 'r') as file:\n\u001b[0;32m    100\u001b[0m #             self.keys = list(file.keys())\n\u001b[0;32m    101\u001b[0m         \n\u001b[0;32m    102\u001b[0m #         if label_csv:\n\u001b[0;32m    103\u001b[0m #             self.labels_df = pd.read_csv(label_csv, low_memory=False)\n\u001b[0;32m    104\u001b[0m #             self.labels_df['isic_id'] = self.labels_df['isic_id'].str.replace('.jpg', '')\n\u001b[0;32m    105\u001b[0m #             self.labels_dict = dict(zip(self.labels_df['isic_id'], self.labels_df['target']))\n\u001b[0;32m    106\u001b[0m #         else:\n\u001b[0;32m    107\u001b[0m #             self.labels_dict = None\n\u001b[0;32m    108\u001b[0m     \n\u001b[0;32m    109\u001b[0m #     def __getitem__(self, index):\n\u001b[0;32m    110\u001b[0m #         with h5py.File(self.file_path, 'r') as file:\n\u001b[0;32m    111\u001b[0m #             key = self.keys[index]\n\u001b[0;32m    112\u001b[0m #             jpeg_data = file[key][()]\n\u001b[0;32m    113\u001b[0m #             image = Image.open(io.BytesIO(jpeg_data))\n\u001b[0;32m    114\u001b[0m #             image = np.array(image)\n\u001b[0;32m    115\u001b[0m         \n\u001b[0;32m    116\u001b[0m #         if self.transform:\n\u001b[1;32m--> 117\u001b[0m #             image = self.transform(image)\n\u001b[0;32m    118\u001b[0m         \n\u001b[0;32m    119\u001b[0m #         if self.labels_dict:\n\u001b[0;32m    120\u001b[0m #             label = self.labels_dict.get(key, -1)  # Use -1 if key not found\n\u001b[0;32m    121\u001b[0m #             return image, label\n\u001b[0;32m    122\u001b[0m #         else:\n\u001b[0;32m    123\u001b[0m #             return image, 0  # For test set without labels\n\u001b[0;32m    124\u001b[0m     \n\u001b[0;32m    125\u001b[0m #     def __len__(self):\n\u001b[0;32m    126\u001b[0m #         return len(self.keys)\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m # def get_loader(batch_size=16, seed=None):\n\u001b[0;32m    129\u001b[0m #     train_dataset = ISIC_2024_HDF5Dataset(TRAIN_DATA_PATH, label_csv=METADATA_CSV_PATH, transform=TRANS_TRAIN)\n\u001b[0;32m    130\u001b[0m #     test_dataset = ISIC_2024_HDF5Dataset(TEST_DATA_PATH, transform=TRANS_TEST)\n\u001b[0;32m    131\u001b[0m     \n\u001b[0;32m    132\u001b[0m #     # Split train dataset into train and validation\n\u001b[0;32m    133\u001b[0m #     train_idx, val_idx = train_test_split(\n\u001b[0;32m    134\u001b[0m #         range(len(train_dataset)),\n\u001b[0;32m    135\u001b[0m #         test_size=0.2,\n\u001b[0;32m    136\u001b[0m #         stratify=[train_dataset[i][1] for i in range(len(train_dataset))],\n\u001b[0;32m    137\u001b[0m #         random_state=seed\n\u001b[0;32m    138\u001b[0m #     )\n\u001b[0;32m    139\u001b[0m     \n\u001b[0;32m    140\u001b[0m #     train_subset = Subset(train_dataset, train_idx)\n\u001b[0;32m    141\u001b[0m #     val_subset = Subset(train_dataset, val_idx)\n\u001b[0;32m    142\u001b[0m     \n\u001b[0;32m    143\u001b[0m #     train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n\u001b[0;32m    144\u001b[0m #     val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m    145\u001b[0m #     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m #     return train_loader, val_loader, test_loader\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_transform.py:50\u001b[0m, in \u001b[0;36mTransform.forward\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[0;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[0;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[0;32m     48\u001b[0m )\n\u001b[1;32m---> 50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mneeds_transform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minpt\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_transform\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_transform_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_transform.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[0;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[0;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[0;32m     53\u001b[0m ]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_geometry.py:612\u001b[0m, in \u001b[0;36mRandomRotation._transform\u001b[1;34m(self, inpt, params)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, inpt: Any, params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    611\u001b[0m     fill \u001b[38;5;241m=\u001b[39m _get_fill(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill, \u001b[38;5;28mtype\u001b[39m(inpt))\n\u001b[1;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_kernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\_transform.py:35\u001b[0m, in \u001b[0;36mTransform._call_kernel\u001b[1;34m(self, functional, inpt, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, functional: Callable, inpt: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     34\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m _get_kernel(functional, \u001b[38;5;28mtype\u001b[39m(inpt), allow_passthrough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\functional\\_utils.py:31\u001b[0m, in \u001b[0;36m_kernel_tv_tensor_wrapper.<locals>.wrapper\u001b[1;34m(inpt, *args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(kernel)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(inpt, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# If you're wondering whether we could / should get rid of this wrapper,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# lost after the first operation due to our own __torch_function__\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# logic.\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_subclass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tv_tensors\u001b[38;5;241m.\u001b[39mwrap(output, like\u001b[38;5;241m=\u001b[39minpt)\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\functional\\_geometry.py:1036\u001b[0m, in \u001b[0;36mrotate_image\u001b[1;34m(image, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[0;32m   1034\u001b[0m theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(matrix, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m   1035\u001b[0m grid \u001b[38;5;241m=\u001b[39m _affine_grid(theta, w\u001b[38;5;241m=\u001b[39minput_width, h\u001b[38;5;241m=\u001b[39minput_height, ow\u001b[38;5;241m=\u001b[39moutput_width, oh\u001b[38;5;241m=\u001b[39moutput_height)\n\u001b[1;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_grid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sr1ja\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\functional\\_geometry.py:628\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[1;34m(img, grid, mode, fill)\u001b[0m\n\u001b[0;32m    626\u001b[0m fill_img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(fill_list, dtype\u001b[38;5;241m=\u001b[39mfloat_img\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mfloat_img\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 628\u001b[0m     float_img \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'bilinear'\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# The following is mathematically equivalent to:\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# img * mask + (1.0 - mask) * fill = img * mask - fill * mask + fill = mask * (img - fill) + fill\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     float_img \u001b[38;5;241m=\u001b[39m float_img\u001b[38;5;241m.\u001b[39msub_(fill_img)\u001b[38;5;241m.\u001b[39mmul_(mask)\u001b[38;5;241m.\u001b[39madd_(fill_img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_df_sample = pd.read_csv(METADATA_CSV_PATH_50kSAMPLE, low_memory=False)\n",
    "\n",
    "train_dl, val_dl, test_dl = get_loader(label_df=meta_df_sample, batch_size=16, seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
