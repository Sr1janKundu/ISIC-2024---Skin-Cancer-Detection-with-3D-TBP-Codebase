{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import os\n",
    "import h5py\n",
    "import csv\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.transforms import v2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants\n",
    "'''\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "CLASSES = 1\n",
    "EPOCHS = 50\n",
    "MIN_EPOCH_TRAIN = 10\n",
    "PATIENCE = 5\n",
    "EPSILON = 0.0005\n",
    "NEG_POS_RATIO = 20\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths dafuk bruh really path eto niche\n",
    "## Kaggle\n",
    "# TRAIN_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n",
    "# TEST_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "# ANNOTATIONS_FILE = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "# MODEL_SAVE_PATH_ = \"/kaggle/working/\"\n",
    "# LOG_FILE_1 = \"/kaggle/working/\"\n",
    "# LOG_FILE_2 = \"/kaggle/working/log_folds.csv\"\n",
    "# RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"/kaggle/input/resnet34-weights/pytorch/nan/1/resnet34-b627a593.pth\"        # change properly\n",
    "# SUBMISSION_FILE_PATH = \"/kaggle/working/submission.csv\"\n",
    "# METRICS_PLOT_SAVE_PATH = \"/kaggle/working/metrics.png\"\n",
    "\n",
    "## Local_Srijan\n",
    "# TRAIN_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\train-image.hdf5\"\n",
    "# TEST_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\test-image.hdf5\"\n",
    "# ANNOTATIONS_FILE = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\train-metadata.csv\"\n",
    "# MODEL_SAVE_PATH_ = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\\"\n",
    "# LOG_FILE_1 = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\\"\n",
    "# LOG_FILE_2 = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\log_folds.csv\"\n",
    "# RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\resnet34-b627a593.pth\"        # change properly\n",
    "# SUBMISSION_FILE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\submission.csv\"\n",
    "# METRICS_PLOT_SAVE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\metrics.png\" \n",
    "\n",
    "# Local_Sruba\n",
    "TRAIN_HDF5_PATH = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\train-image.hdf5\"\n",
    "TEST_HDF5_PATH = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\test-image.hdf5\"\n",
    "ANNOTATIONS_FILE = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\train-metadata.csv\"\n",
    "MODEL_SAVE_PATH_ = \"E:\\\\isic-2024-challenge\\\\\"\n",
    "LOG_FILE_1 = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\\"\n",
    "LOG_FILE_2 = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\log_folds.csv\"\n",
    "RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"E:\\\\isic-2024-challenge\\\\resnet34-b627a593.pth\"        # change properly\n",
    "SUBMISSION_FILE_PATH = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\submission.csv\"\n",
    "METRICS_PLOT_SAVE_PATH = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\metrics.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transformations\n",
    "'''\n",
    "'''Transformations using torchvision.transforms.v2'''\n",
    "data_transforms_v2 = {\n",
    "    \"train\": v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToImage(),\n",
    "        v2.RandomRotation(degrees=(0, 360)),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.ToDtype(torch.float32, scale = True)\n",
    "    ]),\n",
    "    \"test\": v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale = True)\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "data_transforms_album = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"test\": A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataClass\n",
    "'''\n",
    "class ISIC2024_HDF5(Dataset):\n",
    "    '''\n",
    "    with augmentations using torchvision.transforms.v2\n",
    "    '''\n",
    "    def __init__(self, hdf5_path, annotations_df=None, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.annotations_df = annotations_df\n",
    "        self.transform = transform\n",
    "        self.image_ids = []\n",
    "        \n",
    "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            self.image_ids = annotations_df['isic_id']\n",
    "            self.labels = annotations_df.set_index('isic_id')['target'].to_dict()\n",
    "        else:\n",
    "            self.image_ids = list(self.hdf5_file.keys())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]      # PIL\n",
    "        image = Image.open(BytesIO(self.hdf5_file[image_id][()]))\n",
    "        # image = self.load_image(self.hdf5_file[image_id][()])     # cv2\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Check for NaN in image\n",
    "        if torch.isnan(image).any():\n",
    "            print(f\"NaN detected in image {image_id}\")\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            label = self.labels[image_id]\n",
    "            # Check for NaN in label\n",
    "            if np.isnan(label):\n",
    "                print(f\"NaN detected in label for image {image_id}\")\n",
    "            return image, label, image_id\n",
    "        else:\n",
    "            return image, image_id\n",
    "        \n",
    "    # def load_image(self, image_data):                             # cv2\n",
    "    #     # Decode the image data from HDF5 file using OpenCV\n",
    "    #     image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    #     # image = np.transpose(image, (1, 2, 0))  # Convert HxWxC to CxHxW\n",
    "    #     return image\n",
    "    \n",
    "    def close(self):\n",
    "        self.hdf5_file.close()\n",
    "\n",
    "\n",
    "class ISIC2024_HDF5_ALBUM(Dataset):\n",
    "    '''\n",
    "    With augmentations using albumentations \n",
    "    '''\n",
    "    def __init__(self, hdf5_path, annotations_df=None, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.annotations_df = annotations_df\n",
    "        self.transform = transform\n",
    "        self.image_ids = []\n",
    "        \n",
    "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            self.image_ids = annotations_df['isic_id']\n",
    "            self.labels = annotations_df.set_index('isic_id')['target'].to_dict()\n",
    "        else:\n",
    "            self.image_ids = list(self.hdf5_file.keys())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = np.array(Image.open(BytesIO(self.hdf5_file[image_id][()])))\n",
    "        \n",
    "        # image = self.load_image(self.hdf5_file[image_id][()])\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image = self.transform(image=image)[\"image\"]        # Albumentations returns a dictionary with keys like 'image', 'mask', etc., depending on the transformations applied.\n",
    "\n",
    "        # Check for NaN in image\n",
    "        if torch.isnan(image).any():\n",
    "            print(f\"NaN detected in image {image_id}\")\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            label = self.labels[image_id]\n",
    "            # Check for NaN in label\n",
    "            if np.isnan(label):\n",
    "                print(f\"NaN detected in label for image {image_id}\")\n",
    "            return image, label, image_id\n",
    "        else:\n",
    "            return image, image_id\n",
    "        \n",
    "    # def load_image(self, image_data):\n",
    "    #     # Decode the image data from HDF5 file using OpenCV\n",
    "    #     image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    #     # image = np.transpose(image, (1, 2, 0))  # Convert HxWxC to CxHxW\n",
    "    #     return image\n",
    "    \n",
    "    def close(self):\n",
    "        self.hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataLoader\n",
    "'''\n",
    "def get_loader(test_hdf5_path, \n",
    "               train_labels_df = None, \n",
    "               train_hdf5_path = None, \n",
    "               dataset_cls=ISIC2024_HDF5_ALBUM,\n",
    "               train_img_trans=data_transforms_album[\"train\"], \n",
    "               test_img_trans=data_transforms_album[\"test\"], \n",
    "               batch=32, \n",
    "               seed=None):\n",
    "    if train_labels_df is not None and train_hdf5_path is not None:\n",
    "        train_dataset_all = dataset_cls(hdf5_path=train_hdf5_path, annotations_df=train_labels_df, transform=train_img_trans)\n",
    "        test_dataset = dataset_cls(hdf5_path=test_hdf5_path, transform=test_img_trans)\n",
    "\n",
    "        train_annotations_all = train_labels_df\n",
    "        labels = train_annotations_all['target']\n",
    "        splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "        train_idx, val_idx = next(splitter.split(train_annotations_all, labels))\n",
    "        train_subset = Subset(train_dataset_all, train_idx)\n",
    "        val_subset = Subset(train_dataset_all, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "    else:\n",
    "        test_dataset = dataset_cls(hdf5_path=test_hdf5_path, transform=test_img_trans)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "    \n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, learning_rate, train_dl, val_dl, min_epoch_train, patience, epsilon, log_file, model_save_path, criterion = nn.BCEWithLogitsLoss()):\n",
    "    '''\n",
    "    Training function for ISIC-2024 competition data\n",
    "    Parameters:\n",
    "        epochs: Number of epoches\n",
    "        model: Model \n",
    "        learning_rate: model learning rate\n",
    "        train_dl: Training data loader\n",
    "        val_dl: Validation data loader\n",
    "        min_epoch_train: Train for minimum epoches after which early-stopping kicks in\n",
    "        patience: Patience for early-stopping\n",
    "        epsilon: minimum required improvement in order to go on beyond early-stopping\n",
    "        log_file: log file location to save logs\n",
    "        model_save_path: location for saving trained model \n",
    "        criterion: Loss function, defaults to BCE with logit loss function\n",
    "    '''\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)  # Initialize CosineAnnealingLR scheduler\n",
    "    # scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10,  15], gamma=0.1)\n",
    "    multiplier = lambda epoch: 0.75\n",
    "    scheduler = lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=multiplier)      # multiply learning rate with 0.75 each epoch\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_val_pauc = -1.0  # Initialize with a very low value\n",
    "    current_patience = 0  # Initialize patience counter\n",
    "\n",
    "    with open(log_file, \"w\", newline=\"\") as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(['Epoch', 'Learning Rate', 'Training Loss', 'Training Accuracy', 'Validation Loss', 'Validation Accuracy', 'Validation Precision', 'Validation Recall', 'Validation F1 Score', 'Validation pAUC'])\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n | Epoch: {epoch+1}\")\n",
    "            total_loss = 0\n",
    "            num_corr = 0\n",
    "            num_samp = 0\n",
    "            loop = tqdm(train_dl)\n",
    "            model.train()\n",
    "\n",
    "            for batch_idx, (inputs, labels, _) in enumerate(loop):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs).squeeze(1)\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                \n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN loss detected at batch {batch_idx}\")\n",
    "                    continue\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                num_corr += ((preds > 0.5) == labels).sum()\n",
    "                num_samp += preds.size(0)\n",
    "                total_loss += loss.item()\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            avg_loss = total_loss / len(train_dl)\n",
    "            acc = num_corr / num_samp\n",
    "            print(f\"| Epoch {epoch+1}/{epochs} total training loss: {total_loss}, average training loss: {avg_loss}.\")\n",
    "            \n",
    "            print(\"On Validation Data:\")\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc = evaluate(val_dl, model, criterion)\n",
    "            print(\"learning rate:\", scheduler.get_last_lr()[0])\n",
    "            row = [epoch+1, scheduler.get_last_lr()[0], avg_loss, acc.item(), val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "            if epoch + 1 > min_epoch_train:\n",
    "                '''\n",
    "                early-stopping code\n",
    "                '''\n",
    "                if val_pauc > best_val_pauc and (val_pauc - best_val_pauc) > epsilon:\n",
    "                    best_val_pauc = val_pauc\n",
    "                    print(f'Validation pAUC improved by more than {epsilon}, ({best_val_pauc} > {best_val_pauc})); saving model...')\n",
    "                    checkpoint = {\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                    }\n",
    "                    save_checkpoint(checkpoint, model_save_path)\n",
    "                    print(f'Model saved at {model_save_path}')\n",
    "                    current_patience = 0  # Reset patience if there's an improvement\n",
    "                else:\n",
    "                    current_patience += 1\n",
    "                    print(f'Validation pAUC did not improve. Patience left: {patience - current_patience}')\n",
    "                    \n",
    "                    if current_patience >= patience:\n",
    "                        print(f'\\n---Early stopping at epoch {epoch+1}.---')\n",
    "                        break\n",
    "            else:\n",
    "                '''\n",
    "                train for at least min_epoch_train epochs and keep saving best\n",
    "                '''\n",
    "                if val_pauc > best_val_pauc:\n",
    "                    best_val_pauc = val_pauc\n",
    "                    checkpoint = {\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                    }\n",
    "                    save_checkpoint(checkpoint, model_save_path)\n",
    "                    print(f'Model saved at {model_save_path}')\n",
    "\n",
    "            print(f'Current Best Validation pAUC: {best_val_pauc}')\n",
    "\n",
    "            scheduler.step()  # Update learning rate for next epoch\n",
    "        \n",
    "    print('Training complete.')\n",
    "\n",
    "    return best_val_pauc\n",
    "\n",
    "\n",
    "def pauc_above_tpr(y_true, y_pred, min_tpr=0.80):\n",
    "    '''\n",
    "    Custom metric according to competition\n",
    "    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve\n",
    "    https://www.kaggle.com/code/metric/isic-pauc-abovetpr\n",
    "    '''\n",
    "    y_true = abs(np.array(y_true) - 1)\n",
    "    y_pred = -1.0 * np.array(y_pred)\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if np.isnan(y_true).any() or np.isnan(y_pred).any():\n",
    "        print(\"NaN values detected in inputs to pauc_above_tpr\")\n",
    "        return 0\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    max_fpr = 1 - min_tpr\n",
    "\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    \n",
    "    if len(fpr) < 2:\n",
    "        print(\"Warning: Not enough points to compute pAUC. Returning 0.\")\n",
    "        return 0\n",
    "    \n",
    "    partial_auc = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc\n",
    "\n",
    "\n",
    "def evaluate(loader, model, criterion):\n",
    "    '''\n",
    "    Evaluate function for validation set\n",
    "    '''\n",
    "    metric = BinaryF1Score(threshold=0.5).to(DEVICE)\n",
    "    prec = BinaryPrecision(threshold=0.5).to(DEVICE)\n",
    "    recall = BinaryRecall(threshold=0.5).to(DEVICE)\n",
    "    acc = BinaryAccuracy(threshold=0.5).to(DEVICE)\n",
    "    loss = 0.0\n",
    "    num_corr = 0\n",
    "    num_samp = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            \n",
    "            # Check for NaN in outputs\n",
    "            if torch.isnan(outputs).any():\n",
    "                print(\"NaN detected in model outputs\")\n",
    "                continue\n",
    "            \n",
    "            loss += criterion(outputs, labels.float()).item()\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            num_corr += ((preds > 0.5) == labels).sum()\n",
    "            num_samp += preds.size(0)\n",
    "            metric.update(preds, labels)\n",
    "            prec.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            acc.update(preds, labels)\n",
    "            all_preds.extend(preds.cpu().detach().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = loss / len(loader)\n",
    "    accu = float(num_corr) / float(num_samp)\n",
    "    pauc = pauc_above_tpr(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Total loss: {loss}, Average loss: {avg_loss}\")\n",
    "    print(f\"Got {num_corr}/{num_samp} correct with accuracy {accu*100:.2f}\")\n",
    "    print(f\"pAUC above 80% TPR: {pauc:.3f}, Accuracy: {acc.compute().item():.3f}, precision: {prec.compute().item():.3f}, recall: {recall.compute().item():.3f}, F1Score: {metric.compute().item():.3f}\")\n",
    "    model.train()\n",
    "\n",
    "    return avg_loss, acc.compute().item(), prec.compute().item(), recall.compute().item(), metric.compute().item(), pauc\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth\"):\n",
    "    '''\n",
    "    To save model while training \n",
    "    Saves in working directory by default\n",
    "    '''\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "def load_model(model_save_path = None, imagenet_weights_path = None):   # Use this for submission rather than load_checkpoint() defined above\n",
    "    '''\n",
    "    To load model during evaluation on test set\n",
    "    '''\n",
    "    if model_save_path:\n",
    "        model = torchvision.models.resnet34(weights=None)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = torch.nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "        model.load_state_dict(torch.load(model_save_path)[\"state_dict\"])\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "    else:\n",
    "        model = torchvision.models.resnet34(weights=None)\n",
    "        model.load_state_dict(torch.load(imagenet_weights_path))\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_submission(model, test_loader, submission_file_path):\n",
    "    '''\n",
    "    To predict class probabilities on test data and generate submission.csv file\n",
    "    '''\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, image_names in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "            image_ids.extend(image_names)  # Append all image names from the batch\n",
    "\n",
    "    # Check if the lengths match\n",
    "    if len(image_ids) != len(predictions):\n",
    "        print(f\"Warning: Number of image IDs ({len(image_ids)}) does not match number of predictions ({len(predictions)})\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'isic_id': image_ids,\n",
    "        'target': predictions\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(submission_file_path, index=False)\n",
    "    print(f\"Submission file saved to {submission_file_path}\")\n",
    "\n",
    "\n",
    "def visualize_train_images(images, titles=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(f\"{titles[0][i]} (label: {titles[1][i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \"\"\" Usage\n",
    "    indices = np.random.choice(len(train_dataset_album), size=3, replace=False)\n",
    "    images, label, image_ids  = zip(*[train_dataset_album[i] for i in indices])\n",
    "    visualize_train_images(images, titles=[image_ids, label])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def visualize_train_images(images, titles=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(f\"{titles[0][i]} (label: {titles[1][i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\" usage\n",
    "    indices = np.random.choice(len(train_dataset), size=3, replace=False)\n",
    "    images, label, image_ids  = zip(*[train_dataset[i] for i in indices])\n",
    "    visualize_train_images(images, titles=[image_ids, label])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def visualize_test_images(images, titles=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    ''' Usage\n",
    "    indices = np.random.choice(len(test_dataset), size=3, replace=False)\n",
    "    images, image_ids  = zip(*[test_dataset[i] for i in indices])\n",
    "    visualize_test_images(images, titles=image_ids)    \n",
    "    '''\n",
    "\n",
    "\n",
    "def plot_metrics_from_files(file_paths, save_path=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    num_files = len(file_paths)\n",
    "    rows = 3  # Three rows for three types of plots\n",
    "    cols = num_files  # One column per file\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10 * cols, 10))  # Create a grid of subplots\n",
    "    \n",
    "    if num_files == 1:\n",
    "        axes = axes[:, None]\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract relevant columns\n",
    "        epochs = df['Epoch']\n",
    "        learning_rate = df['Learning Rate']\n",
    "        train_loss = df['Training Loss']\n",
    "        valid_loss = df['Validation Loss']\n",
    "        valid_pAUC = df['Validation pAUC']\n",
    "\n",
    "        # Plot training loss and validation loss\n",
    "        axes[0, i].plot(epochs, train_loss, label='Training Loss', marker='o')\n",
    "        axes[0, i].plot(epochs, valid_loss, label='Validation Loss', marker='o')\n",
    "        axes[0, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[0, i].set_xlabel('Epochs')\n",
    "        axes[0, i].set_ylabel('Loss')\n",
    "        axes[0, i].legend()\n",
    "\n",
    "        # Plot epoch vs learning rate\n",
    "        axes[1, i].plot(epochs, learning_rate, label='Learning Rate', marker='o', color='orange')\n",
    "        axes[1, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[1, i].set_xlabel('Epochs')\n",
    "        axes[1, i].set_ylabel('Learning Rate')\n",
    "        axes[1, i].legend()\n",
    "\n",
    "        # Plot validation pAUC\n",
    "        axes[2, i].plot(epochs, valid_pAUC, label='Validation pAUC', marker='o', color='green')\n",
    "        axes[2, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[2, i].set_xlabel('Epochs')\n",
    "        axes[2, i].set_ylabel('Validation pAUC')\n",
    "        axes[2, i].legend()\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to prevent overlap\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)  # Save the figure if a save path is provided\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesgooo():\n",
    "    annotations_df_full = pd.read_csv(ANNOTATIONS_FILE, low_memory=False)\n",
    "    df_positive_all = annotations_df_full[annotations_df_full[\"target\"] == 1].reset_index(drop=True)\n",
    "    df_negative_all = annotations_df_full[annotations_df_full[\"target\"] == 0].reset_index(drop=True)\n",
    "    df_negative_trunc = df_negative_all.sample(df_positive_all.shape[0]*NEG_POS_RATIO)\n",
    "    annotations_df_trunc = pd.concat([df_positive_all, df_negative_trunc]).sample(frac=1).reset_index()\n",
    "    val_pAUC = []\n",
    "    with open(LOG_FILE_2, 'w', newline=\"\") as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(['Fold', \"Model_Name\", \"avg_val_pAUC\"])\n",
    "        for fold in range(FOLDS):\n",
    "            train_dl, val_dl, _ = get_loader(train_labels_df=annotations_df_trunc,\n",
    "                                             train_hdf5_path=TRAIN_HDF5_PATH,\n",
    "                                             test_hdf5_path=TEST_HDF5_PATH)\n",
    "            model_resnet = load_model(imagenet_weights_path=RESNET34_IMAGENET_WEIGHTS_PYTORCH)\n",
    "            print(f\"---------------\\nTraining for fold: {fold+1}:\\n---------------\")\n",
    "            val_pAUC_fold = train(epochs=EPOCHS,\n",
    "                                        model=model_resnet,\n",
    "                                        learning_rate=LEARNING_RATE,\n",
    "                                        train_dl=train_dl,\n",
    "                                        val_dl=val_dl,\n",
    "                                        min_epoch_train=MIN_EPOCH_TRAIN,\n",
    "                                        patience=PATIENCE,\n",
    "                                        epsilon=EPSILON,\n",
    "                                        log_file=os.path.join(LOG_FILE_1, f'log_res34_aug_fold_{fold}.csv'),\n",
    "                                        model_save_path=os.path.join(MODEL_SAVE_PATH_, f'model_resnet34_aug_fold_{fold}.pth'))\n",
    "            val_pAUC.append(val_pAUC_fold)\n",
    "            csv_writer.writerow([fold, os.path.basename(os.path.join(MODEL_SAVE_PATH_, f'model_resnet34_aug_fold_{fold}.pth')), val_pAUC_fold]) # Logging avg pauc for the model trained on each fold\n",
    "    best_model_fold_index = val_pAUC.index(max(val_pAUC))\n",
    "    \n",
    "    file_paths = [os.path.join(LOG_FILE_1, f'log_res34_aug_fold_{i}.csv') for i in range(FOLDS)]\n",
    "    utils.plot_metrics_from_files(file_paths, save_path=METRICS_PLOT_SAVE_PATH)\n",
    "    \n",
    "    return best_model_fold_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Training for fold: 1:\n",
      "---------------\n",
      "\n",
      " | Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:32<00:00,  6.39it/s, loss=0.436] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 1/50 total training loss: 38.17391216009855, average training loss: 0.1844150345898481.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:06<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 9.29320259205997, Average loss: 0.17871543446269172\n",
      "Got 1569/1651 correct with accuracy 95.03\n",
      "pAUC above 80% TPR: 0.059, Accuracy: 0.950, precision: 0.440, recall: 0.139, F1Score: 0.212\n",
      "learning rate: 0.0001\n",
      "=> Saving checkpoint\n",
      "Model saved at E:\\isic-2024-challenge\\model_resnet34_aug_fold_0.pth\n",
      "Current Best Validation pAUC: 0.05850001610461556\n",
      "\n",
      " | Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:28<00:00,  7.27it/s, loss=0.0145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 2/50 total training loss: 26.612846518866718, average training loss: 0.12856447593655418.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:05<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 9.067445961758494, Average loss: 0.17437396080304796\n",
      "Got 1568/1651 correct with accuracy 94.97\n",
      "pAUC above 80% TPR: 0.090, Accuracy: 0.950, precision: 0.438, recall: 0.177, F1Score: 0.252\n",
      "learning rate: 7.500000000000001e-05\n",
      "=> Saving checkpoint\n",
      "Model saved at E:\\isic-2024-challenge\\model_resnet34_aug_fold_0.pth\n",
      "Current Best Validation pAUC: 0.0898879118755435\n",
      "\n",
      " | Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 96/207 [00:12<00:14,  7.43it/s, loss=0.0177]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m IDX \u001b[38;5;241m=\u001b[39m lesgooo()\n",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m, in \u001b[0;36mlesgooo\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m model_resnet \u001b[38;5;241m=\u001b[39m load_model(imagenet_weights_path\u001b[38;5;241m=\u001b[39mRESNET34_IMAGENET_WEIGHTS_PYTORCH)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining for fold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m val_pAUC_fold \u001b[38;5;241m=\u001b[39m train(epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m     18\u001b[0m                             model\u001b[38;5;241m=\u001b[39mmodel_resnet,\n\u001b[0;32m     19\u001b[0m                             learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE,\n\u001b[0;32m     20\u001b[0m                             train_dl\u001b[38;5;241m=\u001b[39mtrain_dl,\n\u001b[0;32m     21\u001b[0m                             val_dl\u001b[38;5;241m=\u001b[39mval_dl,\n\u001b[0;32m     22\u001b[0m                             min_epoch_train\u001b[38;5;241m=\u001b[39mMIN_EPOCH_TRAIN,\n\u001b[0;32m     23\u001b[0m                             patience\u001b[38;5;241m=\u001b[39mPATIENCE,\n\u001b[0;32m     24\u001b[0m                             epsilon\u001b[38;5;241m=\u001b[39mEPSILON,\n\u001b[0;32m     25\u001b[0m                             log_file\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LOG_FILE_1, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_res34_aug_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     26\u001b[0m                             model_save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_SAVE_PATH_, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_resnet34_aug_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     27\u001b[0m val_pAUC\u001b[38;5;241m.\u001b[39mappend(val_pAUC_fold)\n\u001b[0;32m     28\u001b[0m csv_writer\u001b[38;5;241m.\u001b[39mwriterow([fold, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_SAVE_PATH_, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_resnet34_aug_fold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)), val_pAUC_fold]) \u001b[38;5;66;03m# Logging avg pauc for the model trained on each fold\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs, model, learning_rate, train_dl, val_dl, min_epoch_train, patience, epsilon, log_file, model_save_path, criterion)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN loss detected at batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     51\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     52\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[1;32mc:\\Users\\sruba\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sruba\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sruba\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IDX = lesgooo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Paths\n",
    "'''\n",
    "# Kaggle\n",
    "# TEST_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "# MODEL_SAVE_PATH = f\"/kaggle/working/model_resnet34_aug_fold_{IDX}.pth\"\n",
    "# SUBMISSION_FILE_PATH = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "# Srijan\n",
    "# TEST_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\test-image.hdf5\"\n",
    "# MODEL_SAVE_PATH = f\"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\model_resnet34_aug_fold_{IDX}.pth\"\n",
    "# SUBMISSION_FILE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\submission.csv\"\n",
    "\n",
    "# Sruba\n",
    "TEST_HDF5_PATH = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\test-image.hdf5\"\n",
    "MODEL_SAVE_PATH = f\"E:\\\\isic-2024-challenge\\\\model_resnet34_aug_fold_{IDX}.pth\"\n",
    "SUBMISSION_FILE_PATH = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\submission.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    model = load_model(model_save_path=MODEL_SAVE_PATH)\n",
    "    test_loader = get_loader(test_hdf5_path=TEST_HDF5_PATH)\n",
    "    create_submission(model, test_loader, submission_file_path=SUBMISSION_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mwahh ke call krbe eta puchusona ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
