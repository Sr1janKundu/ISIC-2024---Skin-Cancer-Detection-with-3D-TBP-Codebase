{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import h5py\n",
    "# import os\n",
    "# import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.transforms import v2\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as Fa\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants\n",
    "'''\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "CLASSES = 1\n",
    "EPOCH = 50\n",
    "NEG_POS_RATIO = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "## Kaggle\n",
    "# TRAIN_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n",
    "# TEST_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "# ANNOTATIONS_FILE = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "# MODEL_SAVE_PATH = \"/kaggle/working/model_resnet34_aug_2-2.pth\"\n",
    "# LOG_FILE = \"/kaggle/working/log_res34_aug.csv\"\n",
    "# RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"/kaggle/input/resnet34-weights/pytorch/nan/1/resnet34-b627a593.pth\"        # change properly\n",
    "# SUBMISSION_FILE_PATH = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "## Local_Srijan\n",
    "TRAIN_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\train-image.hdf5\"\n",
    "TEST_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\test-image.hdf5\"\n",
    "ANNOTATIONS_FILE = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\train-metadata.csv\"\n",
    "MODEL_SAVE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\model_resnet34_aug_2-2.pth\"\n",
    "LOG_FILE = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\log_res34_aug.csv\"\n",
    "RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\resnet34-b627a593.pth\"        # change properly\n",
    "SUBMISSION_FILE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\submission.csv\"\n",
    "\n",
    "## Local_Sruba\n",
    "# TRAIN_HDF5_PATH = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\train-image.hdf5\"\n",
    "# TEST_HDF5_PATH = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\test-image.hdf5\"\n",
    "# ANNOTATIONS_FILE = \"E:\\\\isic-2024-challenge\\\\Dataset\\\\train-metadata.csv\"\n",
    "# MODEL_SAVE_PATH = \"E:\\\\isic-2024-challenge\\\\model_resnet34_aug_2-2.pth\"\n",
    "# LOG_FILE = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\log_res34_aug.csv\"\n",
    "# RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"E:\\\\isic-2024-challenge\\\\resnet34-b627a593.pth\"        # change properly\n",
    "# SUBMISSION_FILE_PATH = \"E:\\\\isic-2024-challenge\\\\Codebase\\\\Classification_v2\\\\submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df_full = pd.read_csv(ANNOTATIONS_FILE, low_memory=False)\n",
    "df_positive_all = annotations_df_full[annotations_df_full[\"target\"] == 1].reset_index(drop=True)\n",
    "df_negative_all = annotations_df_full[annotations_df_full[\"target\"] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_positive_all.shape, df_negative_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_trunc = df_negative_all.sample(df_positive_all.shape[0]*NEG_POS_RATIO)\n",
    "df_negative_trunc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df_trunc = pd.concat([df_positive_all, df_negative_trunc]).sample(frac=1).reset_index()\n",
    "annotations_df_trunc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataClass\n",
    "'''\n",
    "class ISIC2024_HDF5(Dataset):\n",
    "    def __init__(self, hdf5_path, annotations_df=None, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.annotations_df = annotations_df\n",
    "        self.transform = transform\n",
    "        self.image_ids = []\n",
    "        \n",
    "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            self.image_ids = annotations_df['isic_id']\n",
    "            self.labels = annotations_df.set_index('isic_id')['target'].to_dict()\n",
    "        else:\n",
    "            self.image_ids = list(self.hdf5_file.keys())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = Image.open(BytesIO(self.hdf5_file[image_id][()]))\n",
    "        # image = self.load_image(self.hdf5_file[image_id][()])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Check for NaN in image\n",
    "        if torch.isnan(image).any():\n",
    "            print(f\"NaN detected in image {image_id}\")\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            label = self.labels[image_id]\n",
    "            # Check for NaN in label\n",
    "            if np.isnan(label):\n",
    "                print(f\"NaN detected in label for image {image_id}\")\n",
    "            return image, label, image_id\n",
    "        else:\n",
    "            return image, image_id\n",
    "        \n",
    "    # def load_image(self, image_data):\n",
    "    #     # Decode the image data from HDF5 file using OpenCV\n",
    "    #     image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    #     # image = np.transpose(image, (1, 2, 0))  # Convert HxWxC to CxHxW\n",
    "    #     return image\n",
    "    \n",
    "    def close(self):\n",
    "        self.hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transformations\n",
    "'''\n",
    "TRAIN_TRANS = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.RandomRotation(degrees=(0, 360)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale = True)\n",
    "])\n",
    "TEST_TRANS = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale = True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ISIC2024_HDF5(TRAIN_HDF5_PATH, annotations_df_trunc, transform=TRAIN_TRANS)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ISIC2024_HDF5(TEST_HDF5_PATH, transform=TEST_TRANS)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_images(images, titles=None):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(f\"{titles[0][i]} (label: {titles[1][i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "indices = np.random.choice(len(train_dataset), size=3, replace=False)\n",
    "images, label, image_ids  = zip(*[train_dataset[i] for i in indices])\n",
    "visualize_train_images(images, titles=[image_ids, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test_images(images, titles=None):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "indices = np.random.choice(len(test_dataset), size=3, replace=False)\n",
    "images, image_ids  = zip(*[test_dataset[i] for i in indices])\n",
    "visualize_test_images(images, titles=image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"test\": A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}\n",
    "class ISIC2024_HDF5_ALBUM(Dataset):\n",
    "    def __init__(self, hdf5_path, annotations_df=None, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.annotations_df = annotations_df\n",
    "        self.transform = transform\n",
    "        self.image_ids = []\n",
    "        \n",
    "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            self.image_ids = annotations_df['isic_id']\n",
    "            self.labels = annotations_df.set_index('isic_id')['target'].to_dict()\n",
    "        else:\n",
    "            self.image_ids = list(self.hdf5_file.keys())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = np.array(Image.open(BytesIO(self.hdf5_file[image_id][()])))\n",
    "        \n",
    "        # image = self.load_image(self.hdf5_file[image_id][()])\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image = self.transform(image=image)[\"image\"]        # Albumentations returns a dictionary with keys like 'image', 'mask', etc., depending on the transformations applied.\n",
    "\n",
    "        # Check for NaN in image\n",
    "        if torch.isnan(image).any():\n",
    "            print(f\"NaN detected in image {image_id}\")\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            label = self.labels[image_id]\n",
    "            # Check for NaN in label\n",
    "            if np.isnan(label):\n",
    "                print(f\"NaN detected in label for image {image_id}\")\n",
    "            return image, label, image_id\n",
    "        else:\n",
    "            return image, image_id\n",
    "        \n",
    "    # def load_image(self, image_data):\n",
    "    #     # Decode the image data from HDF5 file using OpenCV\n",
    "    #     image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    #     # image = np.transpose(image, (1, 2, 0))  # Convert HxWxC to CxHxW\n",
    "    #     return image\n",
    "    \n",
    "    def close(self):\n",
    "        self.hdf5_file.close()\n",
    "train_dataset_album = ISIC2024_HDF5_ALBUM(TRAIN_HDF5_PATH, annotations_df_trunc, transform=data_transforms[\"train\"])\n",
    "test_dataset_album = ISIC2024_HDF5_ALBUM(TEST_HDF5_PATH, transform=data_transforms[\"test\"])\n",
    "print(len(train_dataset_album), len(test_dataset_album))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_images(images, titles=None):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(f\"{titles[0][i]} (label: {titles[1][i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "indices = np.random.choice(len(train_dataset_album), size=3, replace=False)\n",
    "images, label, image_ids  = zip(*[train_dataset_album[i] for i in indices])\n",
    "visualize_train_images(images, titles=[image_ids, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataLoader\n",
    "'''\n",
    "def get_loader(dataset_cls=ISIC2024_HDF5_ALBUM,\n",
    "               train_hdf5_path=TRAIN_HDF5_PATH, \n",
    "               test_hdf5_path=TEST_HDF5_PATH, \n",
    "               train_labels_df=annotations_df_trunc, \n",
    "               train_img_trans=data_transforms[\"train\"], \n",
    "               test_img_trans=data_transforms[\"test\"], \n",
    "               batch=32, \n",
    "               seed=None):\n",
    "    \n",
    "    train_dataset_all = dataset_cls(hdf5_path=train_hdf5_path, annotations_df=train_labels_df, transform=train_img_trans)\n",
    "    test_dataset = dataset_cls(hdf5_path=test_hdf5_path, transform=test_img_trans)\n",
    "\n",
    "    train_annotations_all = train_labels_df\n",
    "    labels = train_annotations_all['target']\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "    train_idx, val_idx = next(splitter.split(train_annotations_all, labels))\n",
    "    train_subset = Subset(train_dataset_all, train_idx)\n",
    "    val_subset = Subset(train_dataset_all, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl, test_dl = get_loader(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = torchvision.models.resnet34(weights=None)\n",
    "model_resnet.load_state_dict(torch.load(RESNET34_IMAGENET_WEIGHTS_PYTORCH))\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "model_resnet.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utils\n",
    "'''\n",
    "def pauc_above_tpr(y_true, y_pred, min_tpr=0.80):\n",
    "    y_true = abs(np.array(y_true) - 1)\n",
    "    y_pred = -1.0 * np.array(y_pred)\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if np.isnan(y_true).any() or np.isnan(y_pred).any():\n",
    "        print(\"NaN values detected in inputs to pauc_above_tpr\")\n",
    "        return 0\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    max_fpr = 1 - min_tpr\n",
    "\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    \n",
    "    if len(fpr) < 2:\n",
    "        print(\"Warning: Not enough points to compute pAUC. Returning 0.\")\n",
    "        return 0\n",
    "    \n",
    "    partial_auc = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc\n",
    "\n",
    "def evaluate(loader, model, criterion):\n",
    "    metric = BinaryF1Score(threshold=0.5).to(DEVICE)\n",
    "    prec = BinaryPrecision(threshold=0.5).to(DEVICE)\n",
    "    recall = BinaryRecall(threshold=0.5).to(DEVICE)\n",
    "    acc = BinaryAccuracy(threshold=0.5).to(DEVICE)\n",
    "    loss = 0.0\n",
    "    num_corr = 0\n",
    "    num_samp = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            \n",
    "            # Check for NaN in outputs\n",
    "            if torch.isnan(outputs).any():\n",
    "                print(\"NaN detected in model outputs\")\n",
    "                continue\n",
    "            \n",
    "            loss += criterion(outputs, labels.float()).item()\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            num_corr += ((preds > 0.5) == labels).sum()\n",
    "            num_samp += preds.size(0)\n",
    "            metric.update(preds, labels)\n",
    "            prec.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            acc.update(preds, labels)\n",
    "            all_preds.extend(preds.cpu().detach().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = loss / len(loader)\n",
    "    accu = float(num_corr) / float(num_samp)\n",
    "    pauc = pauc_above_tpr(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Total loss: {loss}, Average loss: {avg_loss}\")\n",
    "    print(f\"Got {num_corr}/{num_samp} correct with accuracy {accu*100:.2f}\")\n",
    "    print(f\"pAUC above 80% TPR: {pauc:.3f}, Accuracy: {acc.compute().item():.3f}, precision: {prec.compute().item():.3f}, recall: {recall.compute().item():.3f}, F1Score: {metric.compute().item():.3f}\")\n",
    "    model.train()\n",
    "\n",
    "    return avg_loss, acc.compute().item(), prec.compute().item(), recall.compute().item(), metric.compute().item(), pauc\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def load_model():\n",
    "    model = torchvision.models.resnet34(weights=None)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH)[\"state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def create_submission(model, test_loader):\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, image_names in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "            image_ids.extend(image_names)  # Append all image names from the batch\n",
    "\n",
    "    # Check if the lengths match\n",
    "    if len(image_ids) != len(predictions):\n",
    "        print(f\"Warning: Number of image IDs ({len(image_ids)}) does not match number of predictions ({len(predictions)})\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'isic_id': image_ids,\n",
    "        'target': predictions\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "    print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Loop\n",
    "'''\n",
    "def train(epochs, model, train_dl, val_dl, patience=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)  # Initialize CosineAnnealingLR scheduler\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    best_val_pauc = -1.0  # Initialize with a very low value\n",
    "    current_patience = 0  # Initialize patience counter\n",
    "    \n",
    "    with open(LOG_FILE, 'w', newline='') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(['Epoch', 'Training Loss', 'Training Accuracy', 'Validation Loss', 'Validation Accuracy', 'Validation Precision', 'Validation Recall', 'Validation F1 Score', 'Validation pAUC'])\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n | Epoch: {epoch+1}\")\n",
    "            total_loss = 0\n",
    "            num_corr = 0\n",
    "            num_samp = 0\n",
    "            loop = tqdm(train_dl)\n",
    "            model.train()\n",
    "            \n",
    "            for batch_idx, (inputs, labels, _) in enumerate(loop):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs).squeeze(1)\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                \n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN loss detected at batch {batch_idx}\")\n",
    "                    continue\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                num_corr += ((preds > 0.5) == labels).sum()\n",
    "                num_samp += preds.size(0)\n",
    "                total_loss += loss.item()\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            avg_loss = total_loss / len(train_dl)\n",
    "            acc = num_corr / num_samp\n",
    "            print(f\"| Epoch {epoch+1}/{epochs} total training loss: {total_loss}, average training loss: {avg_loss}.\")\n",
    "            print(\"On Validation Data:\")\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc = evaluate(val_dl, model, criterion)\n",
    "            \n",
    "            row = [epoch+1, avg_loss, acc.item(), val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc]\n",
    "            csv_writer.writerow(row)\n",
    "            \n",
    "            if val_pauc > best_val_pauc:\n",
    "                best_val_pauc = val_pauc\n",
    "                print(f'Validation pAUC improved ({best_val_pauc} > {best_val_pauc}), saving model...')\n",
    "                checkpoint = {\n",
    "                    \"state_dict\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                }\n",
    "                save_checkpoint(checkpoint, MODEL_SAVE_PATH)\n",
    "                print(f'Model saved at {MODEL_SAVE_PATH}')\n",
    "                current_patience = 0  # Reset patience if there's an improvement\n",
    "            else:\n",
    "                current_patience += 1\n",
    "                print(f'Validation pAUC did not improve. Patience left: {patience - current_patience}')\n",
    "                \n",
    "                if current_patience >= patience:\n",
    "                    print(f'Early stopping at epoch {epoch+1}...')\n",
    "                    break\n",
    "            \n",
    "            print(f'Current Best Validation pAUC: {best_val_pauc}')\n",
    "            \n",
    "            scheduler.step()  # Update learning rate for next epoch\n",
    "        \n",
    "    print('Training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " | Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:14<00:00,  3.41it/s, loss=0.0152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 1/5 total training loss: 41.17228405550122, average training loss: 0.16082923459180165.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:19<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 8.254987146705389, Average loss: 0.1289841741672717\n",
      "Got 1966/2044 correct with accuracy 96.18\n",
      "pAUC above 80% TPR: 0.119, Accuracy: 0.962, precision: 0.667, recall: 0.025, F1Score: 0.049\n",
      "Validation pAUC improved (0.11920765291332493 > 0.11920765291332493), saving model...\n",
      "=> Saving checkpoint\n",
      "Model saved at D:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\model_resnet34_aug_2-2.pth\n",
      "Current Best Validation pAUC: 0.11920765291332493\n",
      "\n",
      " | Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:57<00:00,  4.49it/s, loss=0.00294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 2/5 total training loss: 32.475412633502856, average training loss: 0.12685708059962053.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:13<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 8.968072603456676, Average loss: 0.14012613442901056\n",
      "Got 1972/2044 correct with accuracy 96.48\n",
      "pAUC above 80% TPR: 0.126, Accuracy: 0.965, precision: 0.769, recall: 0.127, F1Score: 0.217\n",
      "Validation pAUC improved (0.12617773053757203 > 0.12617773053757203), saving model...\n",
      "=> Saving checkpoint\n",
      "Model saved at D:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\model_resnet34_aug_2-2.pth\n",
      "Current Best Validation pAUC: 0.12617773053757203\n",
      "\n",
      " | Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:59<00:00,  4.31it/s, loss=0.00644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 3/5 total training loss: 31.58298628637567, average training loss: 0.12337104018115497.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:14<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 9.169907026924193, Average loss: 0.14327979729569051\n",
      "Got 1969/2044 correct with accuracy 96.33\n",
      "pAUC above 80% TPR: 0.132, Accuracy: 0.963, precision: 0.600, recall: 0.152, F1Score: 0.242\n",
      "Validation pAUC improved (0.1316880858053918 > 0.1316880858053918), saving model...\n",
      "=> Saving checkpoint\n",
      "Model saved at D:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\model_resnet34_aug_2-2.pth\n",
      "Current Best Validation pAUC: 0.1316880858053918\n",
      "\n",
      " | Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:26<00:00,  2.97it/s, loss=0.0051] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 4/5 total training loss: 30.217107410775498, average training loss: 0.11803557582334179.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:13<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 8.116062620887533, Average loss: 0.1268134784513677\n",
      "Got 1977/2044 correct with accuracy 96.72\n",
      "pAUC above 80% TPR: 0.123, Accuracy: 0.967, precision: 0.731, recall: 0.241, F1Score: 0.362\n",
      "Validation pAUC did not improve. Patience left: 4\n",
      "Current Best Validation pAUC: 0.1316880858053918\n",
      "\n",
      " | Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:00<00:00,  4.25it/s, loss=0.44]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 5/5 total training loss: 29.243033076869324, average training loss: 0.1142305979565208.\n",
      "On Validation Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:14<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 8.810258953366429, Average loss: 0.13766029614635045\n",
      "Got 1979/2044 correct with accuracy 96.82\n",
      "pAUC above 80% TPR: 0.116, Accuracy: 0.968, precision: 0.750, recall: 0.266, F1Score: 0.393\n",
      "Validation pAUC did not improve. Patience left: 3\n",
      "Current Best Validation pAUC: 0.1316880858053918\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training\n",
    "'''\n",
    "train(epochs=EPOCH, model=model_resnet, train_dl=train_dl, val_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 62.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to D:\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\Codebase\\Classification_v2\\submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Generating submission file\n",
    "'''\n",
    "model = load_model()\n",
    "_, _, test_loader = get_loader()\n",
    "create_submission(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
