{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "import csv\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from tqdm import tqdm\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.transforms import v2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "# from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants\n",
    "'''\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "CLASSES = 1\n",
    "EPOCHS = 15\n",
    "MIN_EPOCH_TRAIN = 5\n",
    "PATIENCE = 5\n",
    "EPSILON = 0.0005\n",
    "NEG_POS_RATIO = 20\n",
    "FOLDS = 5\n",
    "TRAIN_IMAGE = True\n",
    "TRAIN_METADATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle\n",
    "TRAIN_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n",
    "TEST_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "TRAIN_META = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "TEST_META = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n",
    "MODEL_SAVE_PATH_ = \"/kaggle/working/\"\n",
    "LOG_FILE_1 = \"/kaggle/working/\"\n",
    "LOG_FILE_2 = \"/kaggle/working/log_folds.csv\"\n",
    "RESNET34_HAM10000_WEIGHTS_PYTORCH = \"/kaggle/input/resnet34_ham10000_11binary_pretrain/pytorch/july12_24/1/ResNet34_HAM10000_1-1.pth\"        # change properly\n",
    "SUBMISSION_FILE_PATH = \"/kaggle/working/submission.csv\"\n",
    "METRICS_PLOT_SAVE_PATH = \"/kaggle/working/metrics.png\"\n",
    "\n",
    "## Local_Srijan\n",
    "# TRAIN_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\train-image.hdf5\"\n",
    "# TEST_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\test-image.hdf5\"\n",
    "# TRAIN_META = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\train-metadata.csv\"\n",
    "# TEST_META = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\test-metadata.csv\"\n",
    "# MODEL_SAVE_PATH_ = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\\"\n",
    "# LOG_FILE_1 = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\\"\n",
    "# LOG_FILE_2 = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\log_folds.csv\"\n",
    "# RESNET34_HAM10000_WEIGHTS_PYTORCH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\resnet34-b627a593.pth\"        # change properly\n",
    "# SUBMISSION_FILE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\submission.csv\"\n",
    "# METRICS_PLOT_SAVE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\metrics.png\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transformations for Image Data\n",
    "'''\n",
    "data_transforms_album = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"test\": A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataClass for Image Data\n",
    "'''\n",
    "class ISIC2024_HDF5_ALBUM(Dataset):\n",
    "    '''\n",
    "    With augmentations using albumentations \n",
    "    '''\n",
    "    def __init__(self, hdf5_path, annotations_df=None, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.annotations_df = annotations_df\n",
    "        self.transform = transform\n",
    "        self.image_ids = []\n",
    "        \n",
    "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            self.image_ids = annotations_df['isic_id']\n",
    "            self.labels = annotations_df.set_index('isic_id')['target'].to_dict()\n",
    "        else:\n",
    "            self.image_ids = list(self.hdf5_file.keys())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = np.array(Image.open(BytesIO(self.hdf5_file[image_id][()])))\n",
    "        \n",
    "        # image = self.load_image(self.hdf5_file[image_id][()])\n",
    "\n",
    "        if self.transform:\n",
    "            # image = self.transform(image)\n",
    "            image = self.transform(image=image)[\"image\"]        # Albumentations returns a dictionary with keys like 'image', 'mask', etc., depending on the transformations applied.\n",
    "\n",
    "        # Check for NaN in image\n",
    "        if torch.isnan(image).any():\n",
    "            print(f\"NaN detected in image {image_id}\")\n",
    "\n",
    "        if self.annotations_df is not None:\n",
    "            label = self.labels[image_id]\n",
    "            # Check for NaN in label\n",
    "            if np.isnan(label):\n",
    "                print(f\"NaN detected in label for image {image_id}\")\n",
    "            return image, label, image_id\n",
    "        else:\n",
    "            return image, image_id\n",
    "        \n",
    "    # def load_image(self, image_data):\n",
    "    #     # Decode the image data from HDF5 file using OpenCV\n",
    "    #     image = cv2.imdecode(np.frombuffer(image_data, np.uint8), cv2.IMREAD_COLOR)\n",
    "    #     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    #     # image = np.transpose(image, (1, 2, 0))  # Convert HxWxC to CxHxW\n",
    "    #     return image\n",
    "    \n",
    "    def close(self):\n",
    "        self.hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataLoader for Image Data\n",
    "'''\n",
    "def get_loader(test_hdf5_path, \n",
    "               train_labels_df = None, \n",
    "               train_hdf5_path = None, \n",
    "               dataset_cls=ISIC2024_HDF5_ALBUM,\n",
    "               train_img_trans=data_transforms_album[\"train\"], \n",
    "               test_img_trans=data_transforms_album[\"test\"], \n",
    "               n_splits = FOLDS,\n",
    "               batch=32, \n",
    "               seed=42):\n",
    "    if train_labels_df is not None and train_hdf5_path is not None:\n",
    "        train_dataset_all = dataset_cls(hdf5_path=train_hdf5_path, annotations_df=train_labels_df, transform=train_img_trans)\n",
    "        test_dataset = dataset_cls(hdf5_path=test_hdf5_path, transform=test_img_trans)\n",
    "\n",
    "        train_annotations_all = train_labels_df\n",
    "        labels = train_annotations_all['target']\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "        train_loaders, val_loaders = [], []\n",
    "        for train_idx, val_idx in skf.split(train_annotations_all, labels):\n",
    "            train_subset = Subset(train_dataset_all, train_idx)\n",
    "            val_subset = Subset(train_dataset_all, val_idx)\n",
    "            \n",
    "            train_loaders.append(DataLoader(train_subset, batch_size=batch, shuffle=True))\n",
    "            val_loaders.append(DataLoader(val_subset, batch_size=batch, shuffle=True))\n",
    "        \n",
    "        test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "        \n",
    "        return train_loaders, val_loaders, test_loader\n",
    "\n",
    "    else:\n",
    "        test_dataset = dataset_cls(hdf5_path=test_hdf5_path, transform=test_img_trans)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "    \n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaData Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Engineering\n",
    "'''\n",
    "def feature_engineering(df):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
    "    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
    "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n",
    "    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
    "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    \n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
    "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "\n",
    "    new_num_cols = [\n",
    "        \"lesion_size_ratio\", \"lesion_shape_index\", \"hue_contrast\",\n",
    "        \"luminance_contrast\", \"lesion_color_difference\", \"border_complexity\",\n",
    "        \"color_uniformity\", \"3d_position_distance\", \"perimeter_to_area_ratio\",\n",
    "        \"lesion_visibility_score\", \"symmetry_border_consistency\", \"color_consistency\",\n",
    "\n",
    "        \"size_age_interaction\", \"hue_color_std_interaction\", \"lesion_severity_index\", \n",
    "        \"shape_complexity_index\", \"color_contrast_index\", \"log_lesion_area\",\n",
    "        \"normalized_lesion_size\", \"mean_hue_difference\", \"std_dev_contrast\",\n",
    "        \"color_shape_composite_index\", \"3d_lesion_orientation\", \"overall_color_difference\",\n",
    "        \"symmetry_perimeter_interaction\", \"comprehensive_lesion_index\",\n",
    "    ]\n",
    "    new_cat_cols = [\"combined_anatomical_site\"]\n",
    "    return df, new_num_cols, new_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Splits\n",
    "'''\n",
    "def get_stratified_splits(metadata_df, n_splits=FOLDS, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs a stratified split of the provided tabular metadata dataframe.\n",
    "    \n",
    "    Args:\n",
    "        metadata_df (pandas.DataFrame): The tabular metadata dataframe to be split.\n",
    "        n_splits (int, optional): The number of folds to create. Defaults to 5.\n",
    "        random_state (int, optional): The random state for reproducibility. Defaults to 42.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains the train and validation dataframes for a fold.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    splits = []\n",
    "    for train_idx, val_idx in skf.split(metadata_df, metadata_df['target']):\n",
    "        train_df = metadata_df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = metadata_df.iloc[val_idx].reset_index(drop=True)\n",
    "        splits.append((train_df, val_df))\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model\n",
    "'''\n",
    "\n",
    "__n_estimators         = random.choice([1400, 1500, 2000])                  # 800,900,1000,1100,1200,1300,\n",
    "__learning_rate        = random.choice([0.003, 0.002, 0.001])               # 0.005,0.004,\n",
    "__lambda_l1            = random.choice([0.14, 0.21, 0.27, 0.37])\n",
    "__lambda_l2            = random.choice([0.7, 1.0, 1.47, 1.77, 2.77])\n",
    "__pos_bagging_fraction = random.choice([0.74, 0.75, 0.77, 0.777])\n",
    "__neg_bagging_fraction = random.choice([0.04, 0.05, 0.07, 0.077])\n",
    "__feature_fraction     = random.choice([0.5, 0.54, 0.57, 0.7, 0.77, 0.777])\n",
    "__num_leaves           = random.choice([16, 20, 24, 30, 33, 37])            # 24,30,31,32,33,37\n",
    "__min_data_in_leaf     = random.choice([16, 20, 24, 40, 50, 57])            # 40,45,50,55,57\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    \"random_state\": 42,\n",
    "    \"n_estimators\":__n_estimators,\n",
    "    'learning_rate':__learning_rate,\n",
    "    'num_leaves':__num_leaves,\n",
    "    'min_data_in_leaf':__min_data_in_leaf,\n",
    "    'bagging_freq': 1,\n",
    "    'pos_bagging_fraction':__pos_bagging_fraction,\n",
    "    'neg_bagging_fraction':__neg_bagging_fraction,\n",
    "    'feature_fraction':__feature_fraction,\n",
    "    'lambda_l1':__lambda_l1,\n",
    "    'lambda_l2':__lambda_l2,\n",
    "    \"verbosity\": -1,\n",
    "    # \"extra_trees\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_image(epochs, model, learning_rate, train_dl, val_dl, min_epoch_train, patience, epsilon, log_file, model_save_path, criterion = nn.BCEWithLogitsLoss()):\n",
    "    '''\n",
    "    Training function for ISIC-2024 competition data\n",
    "    Parameters:\n",
    "        epochs: Number of epoches\n",
    "        model: Model \n",
    "        learning_rate: model learning rate\n",
    "        train_dl: Training data loader\n",
    "        val_dl: Validation data loader\n",
    "        min_epoch_train: Train for minimum epoches after which early-stopping kicks in\n",
    "        patience: Patience for early-stopping\n",
    "        epsilon: minimum required improvement in order to go on beyond early-stopping\n",
    "        log_file: log file location to save logs\n",
    "        model_save_path: location for saving trained model \n",
    "        criterion: Loss function, defaults to BCE with logit loss function\n",
    "    '''\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)  # Initialize CosineAnnealingLR scheduler\n",
    "    # scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10,  15], gamma=0.1)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    best_val_pauc = -1.0  # Initialize with a very low value\n",
    "    current_patience = 0  # Initialize patience counter\n",
    "\n",
    "    with open(log_file, \"w\", newline=\"\") as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(['Epoch', 'Learning Rate', 'Training Loss', 'Training Accuracy', 'Validation Loss', 'Validation Accuracy', 'Validation Precision', 'Validation Recall', 'Validation F1 Score', 'Validation pAUC'])\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n | Epoch: {epoch+1}\")\n",
    "            total_loss = 0\n",
    "            num_corr = 0\n",
    "            num_samp = 0\n",
    "            loop = tqdm(train_dl)\n",
    "            model.train()\n",
    "\n",
    "            for batch_idx, (inputs, labels, _) in enumerate(loop):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(inputs).squeeze(1)\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                \n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN loss detected at batch {batch_idx}\")\n",
    "                    continue\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                num_corr += ((preds > 0.5) == labels).sum()\n",
    "                num_samp += preds.size(0)\n",
    "                total_loss += loss.item()\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            avg_loss = total_loss / len(train_dl)\n",
    "            acc = num_corr / num_samp\n",
    "            print(f\"| Epoch {epoch+1}/{epochs} total training loss: {total_loss}, average training loss: {avg_loss}.\")\n",
    "            \n",
    "            print(\"On Validation Data:\")\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc = evaluate(val_dl, model, criterion)\n",
    "            print(\"learning rate:\", scheduler.get_last_lr()[0])\n",
    "            row = [epoch+1, scheduler.get_last_lr()[0], avg_loss, acc.item(), val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "            if epoch + 1 > min_epoch_train:\n",
    "                '''\n",
    "                early-stopping code\n",
    "                '''\n",
    "                if val_pauc > best_val_pauc and (val_pauc - best_val_pauc) > epsilon:\n",
    "                    best_val_pauc = val_pauc\n",
    "                    print(f'Validation pAUC improved by more than {epsilon}, ({best_val_pauc} > {best_val_pauc})); saving model...')\n",
    "                    checkpoint = {\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                    }\n",
    "                    save_checkpoint(checkpoint, model_save_path)\n",
    "                    print(f'Model saved at {model_save_path}')\n",
    "                    current_patience = 0  # Reset patience if there's an improvement\n",
    "                else:\n",
    "                    current_patience += 1\n",
    "                    print(f'Validation pAUC did not improve. Patience left: {patience - current_patience}')\n",
    "                    \n",
    "                    if current_patience >= patience:\n",
    "                        print(f'\\n---Early stopping at epoch {epoch+1}.---')\n",
    "                        break\n",
    "            else:\n",
    "                '''\n",
    "                train for at least min_epoch_train epochs and keep saving best\n",
    "                '''\n",
    "                if val_pauc > best_val_pauc:\n",
    "                    best_val_pauc = val_pauc\n",
    "                    checkpoint = {\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                    }\n",
    "                    save_checkpoint(checkpoint, model_save_path)\n",
    "                    print(f'Model saved at {model_save_path}')\n",
    "\n",
    "            print(f'Current Best Validation pAUC: {best_val_pauc}')\n",
    "\n",
    "            scheduler.step()  # Update learning rate for next epoch\n",
    "        \n",
    "    print('Training complete.')\n",
    "\n",
    "    return best_val_pauc\n",
    "\n",
    "\n",
    "def pauc_above_tpr(y_true, y_pred, min_tpr=0.80):\n",
    "    '''\n",
    "    Custom metric according to competition\n",
    "    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve\n",
    "    https://www.kaggle.com/code/metric/isic-pauc-abovetpr\n",
    "    '''\n",
    "    y_true = abs(np.array(y_true) - 1)\n",
    "    y_pred = -1.0 * np.array(y_pred)\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if np.isnan(y_true).any() or np.isnan(y_pred).any():\n",
    "        print(\"NaN values detected in inputs to pauc_above_tpr\")\n",
    "        return 0\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    max_fpr = 1 - min_tpr\n",
    "\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    \n",
    "    if len(fpr) < 2:\n",
    "        print(\"Warning: Not enough points to compute pAUC. Returning 0.\")\n",
    "        return 0\n",
    "    \n",
    "    partial_auc = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc\n",
    "\n",
    "\n",
    "def evaluate(loader, model, criterion):\n",
    "    '''\n",
    "    Evaluate function for validation set\n",
    "    '''\n",
    "    metric = BinaryF1Score(threshold=0.5).to(DEVICE)\n",
    "    prec = BinaryPrecision(threshold=0.5).to(DEVICE)\n",
    "    recall = BinaryRecall(threshold=0.5).to(DEVICE)\n",
    "    acc = BinaryAccuracy(threshold=0.5).to(DEVICE)\n",
    "    loss = 0.0\n",
    "    num_corr = 0\n",
    "    num_samp = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            \n",
    "            # Check for NaN in outputs\n",
    "            if torch.isnan(outputs).any():\n",
    "                print(\"NaN detected in model outputs\")\n",
    "                continue\n",
    "            \n",
    "            loss += criterion(outputs, labels.float()).item()\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            num_corr += ((preds > 0.5) == labels).sum()\n",
    "            num_samp += preds.size(0)\n",
    "            metric.update(preds, labels)\n",
    "            prec.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            acc.update(preds, labels)\n",
    "            all_preds.extend(preds.cpu().detach().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = loss / len(loader)\n",
    "    accu = float(num_corr) / float(num_samp)\n",
    "    pauc = pauc_above_tpr(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Total loss: {loss}, Average loss: {avg_loss}\")\n",
    "    print(f\"Got {num_corr}/{num_samp} correct with accuracy {accu*100:.2f}\")\n",
    "    print(f\"pAUC above 80% TPR: {pauc:.3f}, Accuracy: {acc.compute().item():.3f}, precision: {prec.compute().item():.3f}, recall: {recall.compute().item():.3f}, F1Score: {metric.compute().item():.3f}\")\n",
    "    model.train()\n",
    "\n",
    "    return avg_loss, acc.compute().item(), prec.compute().item(), recall.compute().item(), metric.compute().item(), pauc\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth\"):\n",
    "    '''\n",
    "    To save model while training \n",
    "    Saves in working directory by default\n",
    "    '''\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "def load_model(model_save_path = None, imagenet_weights_path = None):   # Use this for submission rather than load_checkpoint() defined above\n",
    "    '''\n",
    "    To load model during evaluation on test set\n",
    "    '''\n",
    "    if model_save_path:\n",
    "        model = torchvision.models.resnet34(weights=None)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = torch.nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "        model.load_state_dict(torch.load(model_save_path)[\"state_dict\"])\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "    else:\n",
    "        model = torchvision.models.resnet34(weights=None)\n",
    "        model.load_state_dict(torch.load(imagenet_weights_path))\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "        model.to(DEVICE)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_submission(submission_file_path, train_image, train_metadata, image_model = None, test_loader = None, meta_models = None, test_meta = None, train_cols = None, cat_cols = None):\n",
    "    '''\n",
    "    To predict class probabilities on test data and generate submission.csv file\n",
    "    '''\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "    if train_image and not train_metadata:\n",
    "        with torch.no_grad():\n",
    "            for inputs, image_names in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                outputs = image_model(inputs).squeeze(1)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predictions.extend(probs.cpu().numpy())\n",
    "                image_ids.extend(image_names)  # Append all image names from the batch\n",
    "\n",
    "    elif train_metadata and not train_image:\n",
    "        df_test = pd.read_csv(test_meta, low_memory=False)\n",
    "        image_ids = list(df_test['isic_id'])\n",
    "        df_test, _, _ = feature_engineering(df_test.copy())\n",
    "        category_encoder = OrdinalEncoder(\n",
    "            categories='auto',\n",
    "            dtype=int,\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-2,\n",
    "            encoded_missing_value=-1,\n",
    "        )\n",
    "        X_cat = category_encoder.fit_transform(df_test[cat_cols])\n",
    "        for c, cat_col in enumerate(cat_cols):\n",
    "            df_test[cat_col] = X_cat[:, c]\n",
    "        predicted_probabilities_list = []\n",
    "        for model in meta_models:\n",
    "            raw_preds = model.predict(df_test[train_cols])\n",
    "            probs = 1 / (1 + np.exp(-raw_preds))\n",
    "            predicted_probabilities_list.append(probs)\n",
    "#         predictions = np.mean([model.predict(df_test[train_cols]) for model in meta_models], 0)\n",
    "        predictions = np.mean(predicted_probabilities_list, axis=0)\n",
    "        \n",
    "    elif train_image and train_metadata:\n",
    "        predictions_1 = []\n",
    "        predictions_2 = []\n",
    "        # Image part\n",
    "        with torch.no_grad():\n",
    "            for inputs, image_names in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                outputs = image_model(inputs).squeeze(1)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predictions_1.extend(probs.cpu().numpy())\n",
    "                image_ids.extend(image_names)  # Append all image names from the batch\n",
    "        # Meta part\n",
    "        df_test = pd.read_csv(test_meta, low_memory=False)\n",
    "        df_test, _, _ = feature_engineering(df_test.copy())\n",
    "        category_encoder = OrdinalEncoder(\n",
    "            categories='auto',\n",
    "            dtype=int,\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-2,\n",
    "            encoded_missing_value=-1,\n",
    "        )\n",
    "        X_cat = category_encoder.fit_transform(df_test[cat_cols])\n",
    "        for c, cat_col in enumerate(cat_cols):\n",
    "            df_test[cat_col] = X_cat[:, c]\n",
    "        predicted_probabilities_list = []\n",
    "        for model in meta_models:\n",
    "            raw_preds = model.predict(df_test[train_cols])\n",
    "            probs = 1 / (1 + np.exp(-raw_preds))\n",
    "            predicted_probabilities_list.append(probs)\n",
    "#         predictions = np.mean([model.predict(df_test[train_cols]) for model in meta_models], 0)\n",
    "        predictions_2 = np.mean(predicted_probabilities_list, axis=0)\n",
    "\n",
    "        predictions = (predictions_1 + predictions_2) / 2\n",
    "    else:\n",
    "        print(\"Bruh\")\n",
    "\n",
    "    # Check if the lengths match\n",
    "    if len(image_ids) != len(predictions):\n",
    "        print(f\"Warning: Number of image IDs ({len(image_ids)}) does not match number of predictions ({len(predictions)})\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'isic_id': image_ids,\n",
    "        'target': predictions\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(submission_file_path, index=False)\n",
    "    print(f\"Submission file saved to {submission_file_path}\")\n",
    "\n",
    "\n",
    "def visualize_train_images(images, titles=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(f\"{titles[0][i]} (label: {titles[1][i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \"\"\" Usage\n",
    "    indices = np.random.choice(len(train_dataset_album), size=3, replace=False)\n",
    "    images, label, image_ids  = zip(*[train_dataset_album[i] for i in indices])\n",
    "    visualize_train_images(images, titles=[image_ids, label])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def visualize_train_images(images, titles=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(f\"{titles[0][i]} (label: {titles[1][i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\" usage\n",
    "    indices = np.random.choice(len(train_dataset), size=3, replace=False)\n",
    "    images, label, image_ids  = zip(*[train_dataset[i] for i in indices])\n",
    "    visualize_train_images(images, titles=[image_ids, label])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def visualize_test_images(images, titles=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC and convert to numpy\n",
    "        plt.imshow(image)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    ''' Usage\n",
    "    indices = np.random.choice(len(test_dataset), size=3, replace=False)\n",
    "    images, image_ids  = zip(*[test_dataset[i] for i in indices])\n",
    "    visualize_test_images(images, titles=image_ids)    \n",
    "    '''\n",
    "\n",
    "\n",
    "def plot_metrics_from_files(file_paths, save_path=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    num_files = len(file_paths)\n",
    "    rows = 4  # Four rows for four types of plots\n",
    "    cols = num_files  # One column per file\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10 * cols, 10))  # Create a grid of subplots\n",
    "    \n",
    "    if num_files == 1:\n",
    "        axes = axes[:, None]\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract relevant columns\n",
    "        epochs = df['Epoch']\n",
    "        learning_rate = df['Learning Rate']\n",
    "        train_loss = df['Training Loss']\n",
    "        valid_loss = df['Validation Loss']\n",
    "        valid_pAUC = df['Validation pAUC']\n",
    "        valid_acc = df['Validation Accuracy']\n",
    "        valid_prec = df['Validation Precision']\n",
    "        valid_recall = df['Validation Recall']\n",
    "        valid_f1score = df['Validation F1 Score']\n",
    "\n",
    "        # Plot training loss and validation loss\n",
    "        axes[0, i].plot(epochs, train_loss, label='Training Loss', marker='o')\n",
    "        axes[0, i].plot(epochs, valid_loss, label='Validation Loss', marker='o')\n",
    "        axes[0, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[0, i].set_xlabel('Epochs')\n",
    "        axes[0, i].set_ylabel('Loss')\n",
    "        axes[0, i].legend()\n",
    "\n",
    "        # Plot epoch vs learning rate\n",
    "        axes[1, i].plot(epochs, learning_rate, label='Learning Rate', marker='o', color='orange')\n",
    "        axes[1, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[1, i].set_xlabel('Epochs')\n",
    "        axes[1, i].set_ylabel('Learning Rate')\n",
    "        axes[1, i].legend()\n",
    "\n",
    "        # Plot validation pAUC\n",
    "        axes[2, i].plot(epochs, valid_pAUC, label='Validation pAUC', marker='o', color='green')\n",
    "        axes[2, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[2, i].set_xlabel('Epochs')\n",
    "        axes[2, i].set_ylabel('Validation pAUC')\n",
    "        axes[2, i].legend()\n",
    "\n",
    "        # Plot accuracy, precision, recall, f1-score\n",
    "        axes[3, i].plot(epochs, valid_acc, label = \"Validation Accuracy\", marker = 'o')\n",
    "        axes[3, i].plot(epochs, valid_prec, label = \"Validation Precision\", marker = 'o')\n",
    "        axes[3, i].plot(epochs, valid_recall, label = \"Validation Recall\", marker = 'o')\n",
    "        axes[3, i].plot(epochs, valid_f1score, label = \"Validation F1 Score\", marker = 'o')\n",
    "        axes[3, i].set_title(f'File: {file_path.split(\"/\")[-1]}')\n",
    "        axes[3, i].set_xlabel('Epochs')\n",
    "        axes[3, i].set_ylabel('Validation Metrics')\n",
    "        axes[3, i].legend()\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def lesgooo(TRAIN_IMAGE, TRAIN_METADATA):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    annotations_df_full = pd.read_csv(TRAIN_META, low_memory=False)\n",
    "    df_positive_all = annotations_df_full[annotations_df_full[\"target\"] == 1].reset_index(drop=True)\n",
    "    df_negative_all = annotations_df_full[annotations_df_full[\"target\"] == 0].reset_index(drop=True)\n",
    "    df_negative_trunc = df_negative_all.sample(df_positive_all.shape[0]*NEG_POS_RATIO)\n",
    "    annotations_df_trunc = pd.concat([df_positive_all, df_negative_trunc]).sample(frac=1).reset_index()\n",
    "\n",
    "    if TRAIN_IMAGE and not TRAIN_METADATA:\n",
    "        train_loaders, val_loaders, _ = get_loader(\n",
    "            test_hdf5_path=TEST_HDF5_PATH,\n",
    "            train_labels_df=annotations_df_trunc,\n",
    "            train_hdf5_path=TRAIN_HDF5_PATH\n",
    "        )\n",
    "        val_pAUC = []\n",
    "        with open(LOG_FILE_2, 'w', newline=\"\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerow(['Fold', \"Model_Name\", \"avg_val_pAUC\"])\n",
    "            for fold in range(FOLDS):\n",
    "                model_resnet = load_model(model_save_path=RESNET34_HAM10000_WEIGHTS_PYTORCH)\n",
    "                print(f\"---------------\\nTraining for fold: {fold+1}:\\n---------------\")\n",
    "                val_pAUC_fold = train_image(epochs=EPOCHS,\n",
    "                                            model=model_resnet,\n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            train_dl=train_loaders[fold],\n",
    "                                            val_dl=val_loaders[fold],\n",
    "                                            min_epoch_train=MIN_EPOCH_TRAIN,\n",
    "                                            patience=PATIENCE,\n",
    "                                            epsilon=EPSILON,\n",
    "                                            log_file=os.path.join(LOG_FILE_1, f'log_res34_aug_fold_{fold}.csv'),\n",
    "                                            model_save_path=os.path.join(MODEL_SAVE_PATH_, f'model_resnet34_aug_fold_{fold}.pth'))\n",
    "                val_pAUC.append(val_pAUC_fold)\n",
    "                csv_writer.writerow([fold, os.path.basename(os.path.join(MODEL_SAVE_PATH_, f'model_resnet34_aug_fold_{fold}.pth')), val_pAUC_fold]) # Logging avg pauc for the model trained on each fold\n",
    "        best_model_fold_index = val_pAUC.index(max(val_pAUC))\n",
    "        \n",
    "        file_paths = [os.path.join(LOG_FILE_1, f'log_res34_aug_fold_{i}.csv') for i in range(FOLDS)]\n",
    "        plot_metrics_from_files(file_paths, save_path=METRICS_PLOT_SAVE_PATH)\n",
    "\n",
    "        return best_model_fold_index, None, None, None\n",
    "    \n",
    "    \n",
    "    elif TRAIN_METADATA and not TRAIN_IMAGE:\n",
    "        df_train, new_num_cols, new_cat_cols = feature_engineering(annotations_df_trunc)\n",
    "        num_cols = [\n",
    "            'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', \n",
    "            'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', \n",
    "            'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', \n",
    "            'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
    "            'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
    "            'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
    "            'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
    "            'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
    "            'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
    "        ] + new_num_cols\n",
    "        cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"] + new_cat_cols\n",
    "        train_cols = num_cols + cat_cols\n",
    "        category_encoder = OrdinalEncoder(\n",
    "            categories='auto',\n",
    "            dtype=int,\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-2,\n",
    "            encoded_missing_value=-1,\n",
    "        )\n",
    "\n",
    "        X_cat = category_encoder.fit_transform(df_train[cat_cols])\n",
    "        for c, cat_col in enumerate(cat_cols):\n",
    "            df_train[cat_col] = X_cat[:, c]\n",
    "        \n",
    "        splits = get_stratified_splits(df_train)\n",
    "\n",
    "        val_scores = []\n",
    "        meta_models = []\n",
    "        for fold in range(FOLDS):\n",
    "            train_df, val_df = splits[fold]\n",
    "            model_metadata = lgb.LGBMRegressor(**lgb_params)\n",
    "            model_metadata.fit(train_df[train_cols], train_df[\"target\"])\n",
    "            preds = model_metadata.predict(val_df[train_cols])\n",
    "            score = pauc_above_tpr(val_df[\"target\"], preds)\n",
    "            val_scores.append(score)\n",
    "            meta_models.append(model_metadata)\n",
    "            print(f\"\\nFold: {fold+1} - Partial AUC Score: {score:.5f}\")\n",
    "\n",
    "        return None, meta_models, train_cols, cat_cols\n",
    "    \n",
    "\n",
    "    elif TRAIN_IMAGE and TRAIN_METADATA:\n",
    "        # Image part\n",
    "        train_loaders, val_loaders, _ = get_loader(\n",
    "            test_hdf5_path=TEST_HDF5_PATH,\n",
    "            train_labels_df=annotations_df_trunc,\n",
    "            train_hdf5_path=TRAIN_HDF5_PATH\n",
    "        )\n",
    "        val_pAUC = []\n",
    "        with open(LOG_FILE_2, 'w', newline=\"\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerow(['Fold', \"Model_Name\", \"avg_val_pAUC\"])\n",
    "            for fold in range(FOLDS):\n",
    "                model_resnet = load_model(model_save_path=RESNET34_HAM10000_WEIGHTS_PYTORCH)\n",
    "                print(f\"---------------\\nTraining for fold: {fold+1}:\\n---------------\")\n",
    "                val_pAUC_fold = train_image(epochs=EPOCHS,\n",
    "                                            model=model_resnet,\n",
    "                                            learning_rate=LEARNING_RATE,\n",
    "                                            train_dl=train_loaders[fold],\n",
    "                                            val_dl=val_loaders[fold],\n",
    "                                            min_epoch_train=MIN_EPOCH_TRAIN,\n",
    "                                            patience=PATIENCE,\n",
    "                                            epsilon=EPSILON,\n",
    "                                            log_file=os.path.join(LOG_FILE_1, f'log_res34_aug_fold_{fold}.csv'),\n",
    "                                            model_save_path=os.path.join(MODEL_SAVE_PATH_, f'model_resnet34_aug_fold_{fold}.pth'))\n",
    "                val_pAUC.append(val_pAUC_fold)\n",
    "                csv_writer.writerow([fold, os.path.basename(os.path.join(MODEL_SAVE_PATH_, f'model_resnet34_aug_fold_{fold}.pth')), val_pAUC_fold]) # Logging avg pauc for the model trained on each fold\n",
    "        best_model_fold_index = val_pAUC.index(max(val_pAUC))\n",
    "        \n",
    "        file_paths = [os.path.join(LOG_FILE_1, f'log_res34_aug_fold_{i}.csv') for i in range(FOLDS)]\n",
    "        plot_metrics_from_files(file_paths, save_path=METRICS_PLOT_SAVE_PATH)\n",
    "        \n",
    "\n",
    "        # Meta part\n",
    "        df_train, new_num_cols, new_cat_cols = feature_engineering(annotations_df_trunc)\n",
    "        num_cols = [\n",
    "            'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', \n",
    "            'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', \n",
    "            'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', \n",
    "            'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
    "            'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
    "            'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
    "            'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
    "            'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
    "            'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
    "        ] + new_num_cols\n",
    "        cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"] + new_cat_cols\n",
    "        train_cols = num_cols + cat_cols\n",
    "        category_encoder = OrdinalEncoder(\n",
    "            categories='auto',\n",
    "            dtype=int,\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-2,\n",
    "            encoded_missing_value=-1,\n",
    "        )\n",
    "\n",
    "        X_cat = category_encoder.fit_transform(df_train[cat_cols])\n",
    "        for c, cat_col in enumerate(cat_cols):\n",
    "            df_train[cat_col] = X_cat[:, c]\n",
    "        \n",
    "        splits = get_stratified_splits(df_train)\n",
    "\n",
    "        val_scores = []\n",
    "        meta_models = []\n",
    "        for fold in range(FOLDS):\n",
    "            train_df, val_df = splits[fold]\n",
    "            model_metadata = lgb.LGBMRegressor(**lgb_params)\n",
    "            model_metadata.fit(train_df[train_cols], train_df[\"target\"])\n",
    "            preds = model_metadata.predict(val_df[train_cols])\n",
    "            score = pauc_above_tpr(val_df[\"target\"], preds)\n",
    "            val_scores.append(score)\n",
    "            meta_models.append(model_metadata)\n",
    "            print(f\"\\nFold: {fold+1} - Partial AUC Score: {score:.5f}\")\n",
    "\n",
    "        return best_model_fold_index, meta_models, train_cols, cat_cols\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('Bruh')\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_best_idx, meta_models, train_cols, cat_cols = lesgooo(TRAIN_IMAGE, TRAIN_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Image Model: /kaggle/working/model_resnet34_aug_fold_{image_best_idx}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Paths\n",
    "'''\n",
    "# Kaggle\n",
    "TEST_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "MODEL_SAVE_PATH = f\"/kaggle/working/model_resnet34_aug_fold_{image_best_idx}.pth\"\n",
    "SUBMISSION_FILE_PATH = \"/kaggle/working/submission_image.csv\"\n",
    "\n",
    "## Srijan\n",
    "# TEST_HDF5_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Data\\\\test-image.hdf5\"\n",
    "# MODEL_SAVE_PATH = f\"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\model_resnet34_aug_fold_{IDX}.pth\"\n",
    "# SUBMISSION_FILE_PATH = \"D:\\\\ISIC 2024 - Skin Cancer Detection with 3D-TBP\\\\Codebase\\\\Classification_v2\\\\submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(TRAIN_IMAGE, TRAIN_METADATA):\n",
    "    if TRAIN_IMAGE and not TRAIN_METADATA:\n",
    "        mod = load_model(model_save_path=MODEL_SAVE_PATH)\n",
    "        test_loader = get_loader(test_hdf5_path=TEST_HDF5_PATH)\n",
    "        create_submission(image_model = mod,\n",
    "                          test_loader = test_loader, \n",
    "                          submission_file_path=SUBMISSION_FILE_PATH, \n",
    "                          train_image = TRAIN_IMAGE, train_metadata = TRAIN_METADATA)\n",
    "    elif TRAIN_METADATA and not TRAIN_IMAGE:\n",
    "        create_submission(meta_models=meta_models,\n",
    "                          test_meta=TEST_META,\n",
    "                          train_cols=train_cols,\n",
    "                          cat_cols = cat_cols,\n",
    "                          submission_file_path=SUBMISSION_FILE_PATH, \n",
    "                          train_image = TRAIN_IMAGE, train_metadata = TRAIN_METADATA)\n",
    "    elif TRAIN_IMAGE and TRAIN_METADATA:\n",
    "        mod = load_model(model_save_path=MODEL_SAVE_PATH)\n",
    "        test_loader = get_loader(test_hdf5_path=TEST_HDF5_PATH)\n",
    "        create_submission(image_model = mod,\n",
    "                          test_loader = test_loader, \n",
    "                          meta_models=meta_models,\n",
    "                          test_meta=TEST_META,\n",
    "                          train_cols=train_cols,\n",
    "                          cat_cols = cat_cols,\n",
    "                          submission_file_path=SUBMISSION_FILE_PATH, \n",
    "                          train_image = TRAIN_IMAGE, train_metadata = TRAIN_METADATA)\n",
    "    else:\n",
    "        print(\"Bruh\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
