{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet34, randomrotation-randomflip, 224x224 resize, stratified split, focal loss\n",
    "\n",
    "Public Score: 0.037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import h5py\n",
    "# import os\n",
    "# import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.transforms import v2\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants\n",
    "'''\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "CLASSES = 1\n",
    "EPOCH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAIN_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n",
    "TEST_HDF5_PATH = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "ANNOTATIONS_FILE = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "MODEL_SAVE_PATH = \"/kaggle/working/model_resnet34_aug_2-1.pth\"\n",
    "LOG_FILE = \"/kaggle/working/log_res34_aug.csv\"\n",
    "RESNET34_IMAGENET_WEIGHTS_PYTORCH = \"/kaggle/input/resnet34-weights/pytorch/nan/1/resnet34-b627a593.pth\"        # change properly\n",
    "SUBMISSION_FILE_PATH = \"/kaggle/working/submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the dataset\n",
    "print(\"Checking for NaN values in the dataset...\")\n",
    "df = pd.read_csv(ANNOTATIONS_FILE)\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utils\n",
    "'''\n",
    "def pauc_above_tpr(y_true, y_pred, min_tpr=0.80):\n",
    "    y_true = abs(np.array(y_true) - 1)\n",
    "    y_pred = -1.0 * np.array(y_pred)\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if np.isnan(y_true).any() or np.isnan(y_pred).any():\n",
    "        print(\"NaN values detected in inputs to pauc_above_tpr\")\n",
    "        return 0\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    max_fpr = 1 - min_tpr\n",
    "\n",
    "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
    "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
    "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
    "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
    "    fpr = np.append(fpr[:stop], max_fpr)\n",
    "    \n",
    "    if len(fpr) < 2:\n",
    "        print(\"Warning: Not enough points to compute pAUC. Returning 0.\")\n",
    "        return 0\n",
    "    \n",
    "    partial_auc = auc(fpr, tpr)\n",
    "\n",
    "    return partial_auc\n",
    "\n",
    "def evaluate(loader, model):\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2)\n",
    "    metric = BinaryF1Score(threshold=0.5).to(DEVICE)\n",
    "    prec = BinaryPrecision(threshold=0.5).to(DEVICE)\n",
    "    recall = BinaryRecall(threshold=0.5).to(DEVICE)\n",
    "    acc = BinaryAccuracy(threshold=0.5).to(DEVICE)\n",
    "    loss = 0.0\n",
    "    num_corr = 0\n",
    "    num_samp = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(loader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            \n",
    "            # Check for NaN in outputs\n",
    "            if torch.isnan(outputs).any():\n",
    "                print(\"NaN detected in model outputs\")\n",
    "                continue\n",
    "            \n",
    "            preds = torch.sigmoid(outputs)\n",
    "            num_corr += ((preds > 0.5) == labels).sum()\n",
    "            num_samp += preds.size(0)\n",
    "            loss += criterion(outputs, labels.float()).item()\n",
    "            metric.update(preds, labels)\n",
    "            prec.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            acc.update(preds, labels)\n",
    "            all_preds.extend(preds.cpu().detach().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = loss / len(loader)\n",
    "    accu = float(num_corr) / float(num_samp)\n",
    "    pauc = pauc_above_tpr(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Total loss: {loss}, Average loss: {avg_loss}\")\n",
    "    print(f\"Got {num_corr}/{num_samp} correct with accuracy {accu*100:.2f}\")\n",
    "    print(f\"pAUC above 80% TPR: {pauc:.3f}, Accuracy: {acc.compute().item():.3f}, precision: {prec.compute().item():.3f}, recall: {recall.compute().item():.3f}, F1Score: {metric.compute().item():.3f}\")\n",
    "    model.train()\n",
    "\n",
    "    return avg_loss, acc.compute().item(), prec.compute().item(), recall.compute().item(), metric.compute().item(), pauc\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        eps = 1e-7  # Small epsilon to prevent log(0)\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(output, target.float(), reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt + eps) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "        \n",
    "def load_model():\n",
    "    model = torchvision.models.resnet34(weights=None)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH)[\"state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def create_submission(model, test_loader):\n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, image_names in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "            image_ids.extend(image_names)  # Append all image names from the batch\n",
    "\n",
    "    # Check if the lengths match\n",
    "    if len(image_ids) != len(predictions):\n",
    "        print(f\"Warning: Number of image IDs ({len(image_ids)}) does not match number of predictions ({len(predictions)})\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'isic_id': image_ids,\n",
    "        'target': predictions\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "    print(f\"Submission file saved to {SUBMISSION_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transformations\n",
    "'''\n",
    "TRAIN_TRANS = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.RandomRotation(degrees=(0, 360)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale = True)\n",
    "])\n",
    "TEST_TRANS = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale = True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DataClass\n",
    "'''\n",
    "class ISIC2024_HDF5(Dataset):\n",
    "    def __init__(self, hdf5_path, annotations_file=None, transform=None):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.annotations_file = annotations_file\n",
    "        self.transform = transform\n",
    "        self.image_ids = []\n",
    "        \n",
    "        self.hdf5_file = h5py.File(self.hdf5_path, 'r')\n",
    "        self.image_ids = list(self.hdf5_file.keys())\n",
    "\n",
    "        if self.annotations_file is not None:\n",
    "            self.labels = pd.read_csv(annotations_file, low_memory=False).set_index('isic_id')['target'].to_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = Image.open(BytesIO(self.hdf5_file[image_id][()]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Check for NaN in image\n",
    "        if torch.isnan(image).any():\n",
    "            print(f\"NaN detected in image {image_id}\")\n",
    "\n",
    "        if self.annotations_file is not None:\n",
    "            label = self.labels[image_id]\n",
    "            # Check for NaN in label\n",
    "            if np.isnan(label):\n",
    "                print(f\"NaN detected in label for image {image_id}\")\n",
    "            return image, label, image_id\n",
    "        else:\n",
    "            return image, image_id\n",
    "\n",
    "    def close(self):\n",
    "        self.hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Loader\n",
    "'''\n",
    "def get_loader(dataset_cls=ISIC2024_HDF5,\n",
    "               train_hdf5_path=TRAIN_HDF5_PATH, \n",
    "               test_hdf5_path=TEST_HDF5_PATH, \n",
    "               train_labels_file=ANNOTATIONS_FILE, \n",
    "               train_img_trans=TRAIN_TRANS, \n",
    "               test_img_trans=TEST_TRANS, \n",
    "               batch=32, \n",
    "               seed=None):\n",
    "    \n",
    "    train_dataset_all = dataset_cls(hdf5_path=train_hdf5_path, annotations_file=train_labels_file, transform=train_img_trans)\n",
    "    test_dataset = dataset_cls(hdf5_path=test_hdf5_path, transform=test_img_trans)\n",
    "\n",
    "    train_annotations_all = pd.read_csv(train_labels_file, low_memory=False)\n",
    "    labels = train_annotations_all['target']\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "    train_idx, val_idx = next(splitter.split(train_annotations_all, labels))\n",
    "    train_subset = Subset(train_dataset_all, train_idx)\n",
    "    val_subset = Subset(train_dataset_all, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loaders and model definition\n",
    "'''\n",
    "train_dl, val_dl, test_dl = get_loader(batch=BATCH_SIZE, seed=42)\n",
    "model_resnet = torchvision.models.resnet34(weights=None)\n",
    "model_resnet.load_state_dict(torch.load(RESNET34_IMAGENET_WEIGHTS_PYTORCH))\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(in_features=num_ftrs, out_features=1)\n",
    "model_resnet.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Loop\n",
    "'''\n",
    "def train(epochs, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_func = FocalLoss(alpha=0.25, gamma=2)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    with open(LOG_FILE, 'w', newline='') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(['Epoch', 'Training Loss', 'Training Accuracy', 'Validation Loss', 'Validation Accuracy', 'Validation Precision', 'Validation Recall', 'Validation F1 Score', 'Validation pAUC'])\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n | Epoch: {epoch+1}\")\n",
    "            total_loss = 0\n",
    "            num_corr = 0\n",
    "            num_samp = 0\n",
    "            loop = tqdm(train_dl)\n",
    "            model.train()\n",
    "            for batch_idx, (inputs, labels, _) in enumerate(loop):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs).squeeze(1)\n",
    "                    loss = loss_func(outputs, labels.float())\n",
    "                \n",
    "                # Check for NaN in loss\n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"NaN loss detected at batch {batch_idx}\")\n",
    "                    continue\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                num_corr += ((preds > 0.5) == labels).sum()\n",
    "                num_samp += preds.size(0)\n",
    "                total_loss += loss.item()\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            avg_loss = total_loss / len(train_dl)\n",
    "            acc = num_corr / num_samp\n",
    "            print(f\"| Epoch {epoch+1}/{epochs} total training loss: {total_loss}, average training loss: {avg_loss}.\")\n",
    "            print(\"On Validation Data:\")\n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc = evaluate(val_dl, model)\n",
    "            row = [epoch+1, avg_loss, acc.item(), val_loss, val_acc, val_pre, val_rec, val_f1, val_pauc]\n",
    "            csv_writer.writerow(row)\n",
    "            print('Saving model...')\n",
    "            checkpoint = {\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            save_checkpoint(checkpoint, MODEL_SAVE_PATH)\n",
    "            print(f'Model saved at {MODEL_SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train\n",
    "'''\n",
    "train(epochs=EPOCH, model=model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generating submission file\n",
    "'''\n",
    "model = load_model()\n",
    "_, _, test_loader = get_loader()\n",
    "create_submission(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
